{"paperId": "69a712d1edc78140f430fbf372453d07e0f97eed", "url": "https://www.semanticscholar.org/paper/69a712d1edc78140f430fbf372453d07e0f97eed", "title": "Transformer-Based Approaches for Sensor-Based Human Activity Recognition: Opportunities and Challenges", "abstract": "Transformers have excelled in natural language processing and computer vision, paving their way to sensor-based Human Activity Recognition (HAR). Previous studies show that transformers outperform their counterparts exclusively when they harness abundant data or employ compute-intensive optimization algorithms. However, neither of these scenarios is viable in sensor-based HAR due to the scarcity of data in this field and the frequent need to perform training and inference on resource-constrained devices. Our extensive investigation into various implementations of transformer-based versus non-transformer-based HAR using wearable sensors, encompassing more than 500 experiments, corroborates these concerns. We observe that transformer-based solutions pose higher computational demands, consistently yield inferior performance, and experience significant performance degradation when quantized to accommodate resource-constrained devices. Additionally, transformers demonstrate lower robustness to adversarial attacks, posing a potential threat to user trust in HAR.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2410.13605, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "1556564820", "name": "C. Leite"}, {"authorId": "1505781329", "name": "Henry Mauranen"}, {"authorId": "2112920828", "name": "Aziza Zhanabatyrova"}, {"authorId": "2280394019", "name": "Yu Xiao"}]}
{"paperId": "376fa02d5d5bfa5a08ce001a7e5d29cf769f96c9", "url": "https://www.semanticscholar.org/paper/376fa02d5d5bfa5a08ce001a7e5d29cf769f96c9", "title": "P2LHAP: Wearable-Sensor-Based Human Activity Recognition, Segmentation, and Forecast Through Patch-to-Label Seq2Seq Transformer", "abstract": "Traditional deep learning methods struggle to simultaneously segment, recognize, and forecast human activities from sensor data. This limits their usefulness in many fields, such as healthcare and assisted living, where real-time understanding of ongoing and upcoming activities is crucial. This article introduces P2LHAP, a novel Patch-to-Label Seq2Seq framework that tackles all three tasks in an efficient single-task model. P2LHAP divides sensor data streams into a sequence of \u201cpatches,\u201d served as input tokens, and outputs a sequence of patch-level activity labels, including the predicted future activities. A unique smoothing technique based on surrounding patch labels, is proposed to identify activity boundaries accurately. Additionally, P2LHAP learns patch-level representation by sensor signal channel-independent Transformer encoders and decoders. All channels share embedding and Transformer weights across all sequences. Evaluated on the three public datasets, P2LHAP significantly outperforms the state-of-the-art in all three tasks, demonstrating its effectiveness and potential for real-world applications.", "openAccessPdf": {"url": "http://arxiv.org/pdf/2403.08214", "status": "GREEN", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2403.08214, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2291098254", "name": "Shuangjian Li"}, {"authorId": "2072832726", "name": "Tao Zhu"}, {"authorId": "103802625", "name": "Mingxing Nie"}, {"authorId": "2271823433", "name": "Huansheng Ning"}, {"authorId": "2135156455", "name": "Zhenyu Liu"}, {"authorId": "2109222039", "name": "L. Chen"}]}
{"paperId": "4394e581e2fa1685072ebe9e27a026f8f6191c24", "url": "https://www.semanticscholar.org/paper/4394e581e2fa1685072ebe9e27a026f8f6191c24", "title": "A Data Efficient Vision Transformer for Robust Human Activity Recognition from the Spectrograms of Wearable Sensor Data", "abstract": "This study introduces the Data Efficient Separable Transformer (DeSepTr) architecture, a novel framework for Human Activity Recognition (HAR) that utilizes a light-weight computer vision model to train a Vision Transformer (ViT) on spectrograms generated from wearable sensor data. The proposed model achieves strong results on several HAR tasks, including surface condition recognition and activity recognition. Compared to the ResNet-18 model, DeSepTr outperforms by 5.9% on out-of-distribution test data accuracy for surface condition recognition. The framework enables ViTs to learn from limited labeled training data and generalize to data from participants outside of the training cohort, potentially leading to the development of activity recognition models that are robust to the wider population. The results suggest that the DeSepTr architecture can overcome limitations related to the heterogeneity of individuals\u2019 behavior patterns and the weak inductive bias of transformer algorithms.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/SSP53291.2023.10208059?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/SSP53291.2023.10208059, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2149933765", "name": "J. McQuire"}, {"authorId": "2053066638", "name": "Paul Watson"}, {"authorId": "2149933090", "name": "Nick Wright"}, {"authorId": "144783954", "name": "H. Hiden"}, {"authorId": "1980248", "name": "M. Catt"}]}
{"paperId": "32230f95826f9d593d5c97ca5a69effb5b3995be", "url": "https://www.semanticscholar.org/paper/32230f95826f9d593d5c97ca5a69effb5b3995be", "title": "Bi-DeepViT: Binarized Transformer for Efficient Sensor-Based Human Activity Recognition", "abstract": null, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/tmc.2025.3526166?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/tmc.2025.3526166, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2072689432", "name": "Fei Luo"}, {"authorId": "2108667643", "name": "Anna Li"}, {"authorId": "2315262067", "name": "Salabat Khan"}, {"authorId": "2239779461", "name": "Kaishun Wu"}, {"authorId": "50815748", "name": "Lu Wang"}]}
{"paperId": "71baffc5bacc60ab1d7149b6f9be1858847f32bf", "url": "https://www.semanticscholar.org/paper/71baffc5bacc60ab1d7149b6f9be1858847f32bf", "title": "Multimodel Lightweight Transformer Framework for Human Activity Recognition", "abstract": "Human Activity Recognition (HAR) finds extensive application across diverse domains. Yet, its integration into healthcare remains challenging due to disparities between prevailing HAR systems optimized for rudimentary actions in controlled settings and the nuanced behaviors and dynamic conditions pertinent to medical diagnostics. Furthermore, prevailing sensor technologies and deployment scenarios present formidable hurdles regarding wearability and adaptability to heterogeneous environments. While navigating these constraints, this investigation evaluates the requisite monitoring simplicity and system adaptability crucial for medical contexts. A HAR framework is proposed, leveraging a Lightweight Transformer architecture with a multi-sensor fusion strategy employing five Inertial Measurement Units (IMUs) as sensors. A Real-world HAR dataset is assembled to authenticate the system\u2019s suitability, and a comprehensive array of experiments is conducted to showcase its potential utility.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/EMBC53108.2024.10781743?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/EMBC53108.2024.10781743, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2316402828", "name": "Wen Qi"}, {"authorId": "2307334833", "name": "Chengwei Lin"}, {"authorId": "2335908770", "name": "Kun Qian"}]}
{"paperId": "04a5dcceb6034fe9614f44c6f744bcc2e97e6561", "url": "https://www.semanticscholar.org/paper/04a5dcceb6034fe9614f44c6f744bcc2e97e6561", "title": "HAR-STGAN: Human Activity Recognition-Spatial Transformer network for Generative Adversarial Network", "abstract": "In this study, we tackle the critical challenge of imbalanced human acivity datasets, which has long hindered the advancement of human activity recognition (HAR) systems. To address this issue, we propose a novel multi-sensor data synthesis method based on generative adversarial networks (GANs). This innovative approach allows us to synthetically generate high-quality data for underrepresented behaviors, thereby balancing the dataset and enhancing the performance of downstream HAR tasks. Recognizing the importance of preserving the inherent relationships between sensor modalities, our algorithm considers the common features shared across multiple sensors. Through a spatial transformation mechanism, we are able to seamlessly translate the characteristics of different wearable sensors, ensuring the generated data maintains a high degree of consistency and specificity. To further bolster the authenticity and diversity of the synthetic data, we incorporate an auxiliary classifier that discriminates between real and generated samples. The classification loss is then seamlessly integrated into the GAN's training objective, providing valuable guidance for the network's optimization. Extensive evaluations across three key dimensions - temporal dynamics, data similarity, and category differentiation - demonstrate the HAR-STGAN algorithm's superior performance compared to state-of-the-art alternatives.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICETIS61828.2024.10593790?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICETIS61828.2024.10593790, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2184496033", "name": "Aixin Nian"}, {"authorId": "2158321043", "name": "Songping Huang"}, {"authorId": "2148955611", "name": "Fei Wang"}, {"authorId": "2184708294", "name": "Yu Zhao"}]}
{"paperId": "6a3357140bda4262cee9bbc0d7ea96e94bfa8003", "url": "https://www.semanticscholar.org/paper/6a3357140bda4262cee9bbc0d7ea96e94bfa8003", "title": "MaskCAE: Masked Convolutional AutoEncoder via Sensor Data Reconstruction for Self-Supervised Human Activity Recognition", "abstract": "Self-supervised Human Activity Recognition (HAR) has been gradually gaining a lot of attention in ubiquitous computing community. Its current focus primarily lies in how to overcome the challenge of manually labeling complicated and intricate sensor data from wearable devices, which is often hard to interpret. However, current self-supervised algorithms encounter three main challenges: performance variability caused by data augmentations in contrastive learning paradigm, limitations imposed by traditional self-supervised models, and the computational load deployed on wearable devices by current mainstream transformer encoders. To comprehensively tackle these challenges, this paper proposes a powerful self-supervised approach for HAR from a novel perspective of denoising autoencoder, the first of its kind to explore how to reconstruct masked sensor data built on a commonly employed, well-designed, and computationally efficient fully convolutional network. Extensive experiments demonstrate that our proposed Masked Convolutional AutoEncoder (MaskCAE) outperforms current state-of-the-art algorithms in self-supervised, fully supervised, and semi-supervised situations without relying on any data augmentations, which fills the gap of masked sensor data modeling in HAR area. Visualization analyses show that our MaskCAE could effectively capture temporal semantics in time series sensor data, indicating its great potential in modeling abstracted sensor data. An actual implementation is evaluated on an embedded platform.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JBHI.2024.3373019?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JBHI.2024.3373019, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2216897261", "name": "Dongzhou Cheng"}, {"authorId": "2152830323", "name": "Lei Zhang"}, {"authorId": "2290076165", "name": "Lutong Qin"}, {"authorId": "2146295154", "name": "Shuoyuan Wang"}, {"authorId": "2254288040", "name": "Hao Wu"}, {"authorId": "2119319577", "name": "Aiguo Song"}]}
{"paperId": "7f46965cca643d65e003ced191550071ce29fac0", "url": "https://www.semanticscholar.org/paper/7f46965cca643d65e003ced191550071ce29fac0", "title": "Human Activity Recognition based on Transformer in Smart Home", "abstract": "With the advancement of artificial intelligence, smart home has attracted much attention from scholars. Human Activity Recognition (HAR) is a crucial foundation for various applications in smart home. In this paper, to improve the accuracy of HAR and promote the development of applications and services in smart home, we propose a Transformer-based approach that integrates multiple sensor sequence inputs for HAR. We integrate sequence features, collect contextual information, and employ Transformer to recognize various activities for the CASAS Aruba dataset that uses environmental sensors. The validation results on real-world dataset demonstrate its effectiveness compared to traditional machine learning and deep learning methods.", "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3590003.3590100", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1145/3590003.3590100?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3590003.3590100, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Book", "JournalArticle"], "authors": [{"authorId": "2218514815", "name": "Xinmei Huang"}, {"authorId": "38654394", "name": "Shenmin Zhang"}]}
{"paperId": "356f045aec87a2e5605168c9f80eb4f2b0b37cfb", "url": "https://www.semanticscholar.org/paper/356f045aec87a2e5605168c9f80eb4f2b0b37cfb", "title": "A Hybrid Visual Transformer for Efficient Deep Human Activity Recognition", "abstract": "Human Activity Recognition (HAR) has gained significant attention in recent years due to its wide-ranging applications. This paper introduces a novel hybrid visual transformer methodology designed to enhance the robust analysis and comprehension of activities. CVTN (Convolution Visual Transformer Network) leverages sensor data represented jointly in spatial and temporal dimensions to enhance the resilience of the HAR process. The proposed technique employs a hybrid model that integrates Convolutional Neural Networks (CNNs) and Visual Transformers (VTs). Initially, the CNN component learns spatial visual features from diverse sensor data. Subsequently, these acquired visual features are inputted into the transformer segment of the model. VT captures temporal insights by observing sensor statuses across different time points. The efficacy of the CVTN methodology is assessed using the Kinetics dataset, which emulates real-world human activity recognition scenarios. The experimental results reveal clear superiority compared to the recent baseline HAR solutions, reaffirming its potential for advancing activity analysis.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCVW60793.2023.00080?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCVW60793.2023.00080, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2816085", "name": "Y. Djenouri"}, {"authorId": "1768812", "name": "A. Belbachir"}]}
{"paperId": "913790f1310dba765b7a4db069a4b59935966342", "url": "https://www.semanticscholar.org/paper/913790f1310dba765b7a4db069a4b59935966342", "title": "GAFormer: Wearable IMU-Based Human Activity Recognition with Gramian Angular Field and Transformer", "abstract": "Recognizing human activities (HAR) from wearable motion sensors has widely practical applications due to its low cost, convenient use, and scalability. Plenty of works utilize 1D CNN or RNN to capture temporal information from time series, while others take advantage of 2D CNN architectures that can effectively handle spatial correlation, and distinctive recognition features, which are really useful for recognition tasks. This paper proposes GAFormer, a method, which exploits the latter, for human activity recognition from wearable motion sensors. GAFormer transforms the raw IMU data into a Gramian Angular Difference Field (GADF) image, which encodes the pair-wise angles between different sensor readings to capture the temporal dynamics and relationships among the sensor measurements. Next, a transformer model is employed to extract visual features from GADF images effectively. In addition, we adapted a state-of-the-art transformer CoAtNet as the backbone of GAFormer. GAFormer is evaluated over two published datasets C-MHAD and GesHome. With the accuracies of 98% on C-MHAD and 95.5% on GesHome\u2019s subset, GAFormer demonstrates that combining the GADF technique and a transformer model could be feasible and promising for motion sensor-based action recognition.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/APSIPAASC58517.2023.10317315?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/APSIPAASC58517.2023.10317315, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2067953701", "name": "Trung-Hieu Le"}, {"authorId": "2267747797", "name": "Thai-Khanh Nguyen"}, {"authorId": "2269120544", "name": "Trung-Kien Tran"}, {"authorId": "2269120546", "name": "Thanh-Hai Tran"}, {"authorId": "2267521570", "name": "Cuong Pham"}]}
{"paperId": "5eb4f22bbd475ce56f081d7f9ea6c1a800130d4b", "url": "https://www.semanticscholar.org/paper/5eb4f22bbd475ce56f081d7f9ea6c1a800130d4b", "title": "Human Activity Recognition on Smartphone Using Transformer Network", "abstract": "Automatic behaviour inspection for sports players, older people, and applications for 1OT require sensor-based human activity identification. Conventional means rely on finger features to tend to fluctuate from raw data using preset mathematical concepts and therefore are incapable of domain adaptation. We proposed a Transformer network in this study to recognize six human actions from Smartphone data. Each participant did several activities while holding a Mobile device around their waist (moving, going up, and coming down, resting, constant, and set down). We first should define the Titans model using the Tensor Flow backend module the tests were recorded and labelled manually and partitioned randomly into two groups. Furthermore, the activity of the project has been examined.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICRT57042.2023.10146656?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICRT57042.2023.10146656, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2220680191", "name": "Sachin Singh"}, {"authorId": "2110937630", "name": "Arjun Singh"}, {"authorId": "2220059911", "name": "Vikrant Rana"}, {"authorId": "2220063029", "name": "Shobhit Prajapati"}, {"authorId": "2220060547", "name": "Saurabh Bhardwaj"}, {"authorId": "2220060553", "name": "Pawan Kr. Pal"}]}
{"paperId": "87e7834eb0b862493b4038e9e0f6303daa0e624b", "url": "https://www.semanticscholar.org/paper/87e7834eb0b862493b4038e9e0f6303daa0e624b", "title": "GeXSe (Generative Explanatory Sensor System): An Interpretable Deep Generative Model for Human Activity Recognition in Smart Spaces", "abstract": null, "openAccessPdf": {"url": "", "status": null, "license": null}, "publicationTypes": null, "authors": [{"authorId": "1655412132", "name": "Yuan Sun"}, {"authorId": "2216343480", "name": "Nandana Pai"}, {"authorId": "2220738589", "name": "Viswa Vijeth Ramesh"}, {"authorId": "49346549", "name": "Murtadha M. N. Aldeer"}, {"authorId": "145291788", "name": "Jorge Ortiz"}]}
{"paperId": "1a9a4c7fe39d655cef4783a438c33e39f8a1c28d", "url": "https://www.semanticscholar.org/paper/1a9a4c7fe39d655cef4783a438c33e39f8a1c28d", "title": "MSMFT: Multi-Stream Multimodal Factorized Transformer for Human Activity Recognition", "abstract": "Existing video-based human activity recognition (HAR) methods are susceptible to challenges such as lighting variations and occlusions in complex environments. Wearable sensors can effectively mitigate these issues. The fusion of the two can reduce environmental impacts, thus enhancing accuracy. However, the heterogeneity between the two data types presents a challenge for fusion. To address this, we propose an architecture called multi-stream multimodal factorized transformer (MSMFT), which leverages the aggregation capabilities of transformers to achieve alignment and fusion of multimodal features without relying on specific feature extractors. First, we designed a statistical feature projection (SFP) method to effectively tokenize wearable sensor data for transformer models. Second, we introduced temporal embedding (TE) to capture local temporal feature variations. Then, we incorporated a factorized transformer architecture that includes temporal and spatial transformer encoders (STEs) to extract global spatiotemporal features fully. Finally, to avoid the issue of modality entanglement caused by deep fusion, we constructed a multi-stream architecture comprising a video stream, wearable sensors stream, and fusion stream. This design allows for the extraction of both independent and interactive modality features. The performance of the MSMFT method was evaluated on three multimodal datasets: UP-Fall, UTD-MHAD, and MMAct. The results show that MSMFT performs better than the state-of-the-art, with a 16.83% improvement in cross-scene F1-score on the MMAct dataset.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JSEN.2025.3529889?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JSEN.2025.3529889, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2341809789", "name": "Xianfa Zhou"}, {"authorId": "2248043894", "name": "Jiabin Yuan"}, {"authorId": "2147259690", "name": "Lili Fan"}, {"authorId": "2057835272", "name": "Xuewei Niu"}, {"authorId": "121481696", "name": "Ke-Ling Zha"}, {"authorId": "2291705516", "name": "Xu Liu"}]}
{"paperId": "ed27624385f2d12d81e2dba1508bbbe6e839dfe0", "url": "https://www.semanticscholar.org/paper/ed27624385f2d12d81e2dba1508bbbe6e839dfe0", "title": "Enhancing the Transformer Model with a Convolutional Feature Extractor Block and Vector-Based Relative Position Embedding for Human Activity Recognition", "abstract": "The Transformer model has received significant attention in Human Activity Recognition (HAR) due to its self-attention mechanism that captures long dependencies in time series. However, for Inertial Measurement Unit (IMU) sensor time-series signals, the Transformer model does not effectively utilize the a priori information of strong complex temporal correlations. Therefore, we proposed using multi-layer convolutional layers as a Convolutional Feature Extractor Block (CFEB). CFEB enables the Transformer model to leverage both local and global time series features for activity classification. Meanwhile, the absolute position embedding (APE) in existing Transformer models cannot accurately represent the distance relationship between individuals at different time points. To further explore positional correlations in temporal signals, this paper introduces the Vector-based Relative Position Embedding (vRPE), aiming to provide more relative temporal position information within sensor signals for the Transformer model. Combining these innovations, we conduct extensive experiments on three HAR benchmark datasets: KU-HAR, UniMiB SHAR, and USC-HAD. Experimental results demonstrate that our proposed enhancement scheme substantially elevates the performance of the Transformer model in HAR.", "openAccessPdf": {"url": "", "status": null, "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11768122, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2305487003", "name": "Xin Guo"}, {"authorId": "2152651406", "name": "Young Kim"}, {"authorId": "2305385444", "name": "Xueli Ning"}, {"authorId": "2161662807", "name": "Sedong Min"}]}
{"paperId": "77febcde7c2e8b6d94cc24332ff038b200f3ebff", "url": "https://www.semanticscholar.org/paper/77febcde7c2e8b6d94cc24332ff038b200f3ebff", "title": "GeXSe (Generative Explanatory Sensor System): An Interpretable Deep Generative Model for Human Activity Recognition in Smart Spaces", "abstract": "We introduce GeXSe (Generative Explanatory Sensor System), a novel framework designed to extract interpretable sensor-based and vision domain features from non-invasive smart space sensors. We combine these to provide a comprehensive explanation of sensor-activation patterns in activity recognition tasks. This system leverages advanced machine learning architectures, including transformer blocks, Fast Fourier Convolution (FFC), and diffusion models, to provide a more detailed understanding of sensor-based human activity data. A standout feature of GeXSe is our unique Multi-Layer Perceptron (MLP) with linear, ReLU, and normalization layers, specially devised for optimal performance on small datasets. It also yields meaningful activation maps to explain sensor-based activation patterns. The standard approach is based on a CNN model, which our MLP model outperforms.GeXSe offers two types of explanations: sensor-based activation maps and visual domain explanations using short videos. These methods offer a comprehensive interpretation of the output from non-interpretable sensor data, thereby augmenting the interpretability of our model. Utilizing the Frechet Inception Distance (FID) for evaluation, it outperforms established methods, improving baseline performance by about 6\\%. GeXSe also achieves a high F1 score of up to 0.85, demonstrating precision, recall, and noise resistance, marking significant progress in reliable and explainable smart space sensing systems.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2306.15857, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": null, "authors": [{"authorId": "2344590247", "name": "Sun Yuan"}, {"authorId": "2343851551", "name": "Salami Pargoo Navid"}, {"authorId": "2336957770", "name": "Ortiz Jorge"}]}
{"paperId": "40faf6719c9ac4c218a5a98d6bbadf2d3da04a4e", "url": "https://www.semanticscholar.org/paper/40faf6719c9ac4c218a5a98d6bbadf2d3da04a4e", "title": "Robust Human Activity Recognition for Intelligent Transportation Systems Using Smartphone Sensors: A Position-Independent Approach", "abstract": "This study explores Human Activity Recognition (HAR) using smartphone sensors to address the challenges posed by position-dependent datasets. We propose a position-independent system that leverages data from accelerometers, gyroscopes, linear accelerometers, and gravity sensors collected from smartphones placed either on the chest or in the left/right leg pocket. The performance of traditional machine learning algorithms (Decision Trees (DT), K-Nearest Neighbors (KNN), Random Forest (RF), Support Vector Classifier (SVC), and XGBoost) is compared against deep learning models (Gated Recurrent Unit (GRU), Long Short-Term Memory (LSTM), Temporal Convolutional Networks (TCN), and Transformer models) under two sensor configurations. Our findings highlight that the Temporal Convolutional Network (TCN) model consistently outperforms other models, particularly in the four-sensor non-overlapping configuration, achieving the highest accuracy of 97.70%. Deep learning models such as LSTM, GRU, and Transformer also demonstrate strong performance, showcasing their effectiveness in capturing temporal dependencies in HAR tasks. Traditional machine learning models, including RF and XGBoost, provide reasonable performance but do not match the accuracy of deep learning models. Additionally, incorporating data from linear accelerometers and gravity sensors led to slight improvements over using accelerometer and gyroscope data alone. This research enhances the recognition of passenger behaviors for intelligent transportation systems, contributing to more efficient congestion management and emergency response strategies.", "openAccessPdf": {"url": "https://www.mdpi.com/2076-3417/14/22/10461/pdf?version=1731575909", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app142210461?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app142210461, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2330664879", "name": "John Benedict Lazaro Bernardo"}, {"authorId": "1804347", "name": "A. Taparugssanagorn"}, {"authorId": "2300777984", "name": "Hiroyuki Miyazaki"}, {"authorId": "7830051", "name": "Bipun Man Pati"}, {"authorId": "2297767823", "name": "Ukesh Thapa"}]}
{"paperId": "8bff28d40f95f9e38860b709b17e026f451a0f8c", "url": "https://www.semanticscholar.org/paper/8bff28d40f95f9e38860b709b17e026f451a0f8c", "title": "GLULA: Linear attention-based model for efficient human activity recognition from wearable sensors", "abstract": "Abstract Body-worn sensor data is used in monitoring patient activity during rehabilitation and also can be extended to controlling rehabilitation devices based on the activity of the person. The primary focus of research has been on effectively capturing the spatiotemporal dependencies in the data collected by these sensors and efficiently classifying human activities. With the increasing complexity and size of models, there is a growing emphasis on optimizing their efficiency in terms of memory usage and inference time for real-time usage and mobile computers. While hybrid models combining convolutional and recurrent neural networks have shown strong performance compared to traditional approaches, self-attention-based networks have demonstrated even superior results. However, instead of relying on the same transformer architecture, there is an opportunity to develop a novel framework that incorporates recent advancements to enhance speed and memory efficiency, specifically tailored for human activity recognition (HAR) tasks. In line with this approach, we present GLULA, a unique architecture for HAR. GLULA combines gated convolutional networks, branched convolutions, and linear self-attention to achieve efficient and powerful solutions. To enhance the performance of our proposed architecture, we employed manifold mixup as an augmentation variant which proved beneficial in limited data settings. Extensive experiments were conducted on five benchmark datasets: PAMAP2, SKODA, OPPORTUNITY, DAPHNET, and USC-HAD. Our findings demonstrate that GLULA outperforms recent models in the literature on the latter four datasets but also exhibits the lowest parameter count and close to the fastest inference time among state-of-the-art models.", "openAccessPdf": {"url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/85AD23F879EAA024691C234891AFB34F/S2631717624000057a.pdf/div-class-title-glula-linear-attention-based-model-for-efficient-human-activity-recognition-from-wearable-sensors-div.pdf", "status": "GOLD", "license": "CCBYNCND", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11016367, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2295371496", "name": "Aldiyar Bolatov"}, {"authorId": "83860067", "name": "A. Yessenbayeva"}, {"authorId": "2191243874", "name": "Adnan Yazici"}]}
{"paperId": "730ec59d69b857d5fe9dea4104ecce495d9bf232", "url": "https://www.semanticscholar.org/paper/730ec59d69b857d5fe9dea4104ecce495d9bf232", "title": "ProbSparse Attention with Stacked Group Convolution for Wireless Signal-Based Human Activity Recognition", "abstract": "With the advancement of Internet of Things, WiFi signal-based Human Activity Recognition (HAR) has demonstrated great potential in various domains. Existing WiFi-based HAR systems pursue high recognition accuracy, but often struggle in achieving model lightweightness. To address this issue, we jointly consider the spatial-temporal correlations of WiFi channel state information. Our proposed HAR method employs an encoder-only Transformer with ProbSparse attention to extract crucial global features from time-series sensor data. Furthermore, it utilizes a stacked group convolutional structure to further encode local temporal and spatial features, respectively, thereby realizing effective extraction of key spatial and temporal characteristics, as well as fusion of global and local features. Experimental results demonstrate that the proposed model achieves an exceptional mean average precision exceeding 99.9% for action recognition across two public datasets: NTU-Fi HAR and NTU-Fi Human-ID, outperforming several state-of-the-art models such as ViT, TCN and BiLSTM. Meanwhile, utilizing ProbSparse attention, our model exhibits a significant improvement in training complexity compared to several state-of-the-art models such as ResNet50, vanilla Transformer, ViT and TCN.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/WCSP62071.2024.10827307?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/WCSP62071.2024.10827307, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2340233578", "name": "Dao Yi"}, {"authorId": "2340353917", "name": "Haiwei Zhang"}, {"authorId": "10717971", "name": "Shaohan Feng"}, {"authorId": "2295119673", "name": "Jinxiang Fang"}, {"authorId": "2282357900", "name": "Wenbo Wang"}]}
{"paperId": "80d063c8d34d0201464e938c19f0c90431e00665", "url": "https://www.semanticscholar.org/paper/80d063c8d34d0201464e938c19f0c90431e00665", "title": "Multi-scale Context-Aware Networks Based on Fragment Association for Human Activity Recognition", "abstract": "Sensor-based Human Activity Recognition (HAR) constitutes a key component of many artificial intelligence applications. Although deep feature extraction technology is constantly updated and iterated with excellent results, it is still a difficult task to find a balance between performance and computational efficiency. Through an in-depth exploration of the inherent characteristics of HAR data, we propose a lightweight feature perception model, which encompasses an internal feature extractor and a contextual feature perceiver. The model mainly consists of two stages. The first stage is a hierarchical multi-scale feature extraction module, which is composed of deep separable convolution and multi-head attention mechanism. This module serves to extract conventional features for Human Activity Recognition. After the feature goes through a fragment recombination operation, it is passed into the Context-Aware module of the second stage, which is based on Retentive Transformer and optimized by Dropkey method to efficiently extract the relationship between the feature fragments, so as to mine more valuable feature information. Importantly, this does not add too much complexity to the model, thereby preventing excessive resource consumption. We conducted extensive experimental validation on multiple publicly available HAR datasets.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.24963/ijcai.2024/351?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.24963/ijcai.2024/351, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2830834", "name": "Zhiqiong Wang"}, {"authorId": "2266144536", "name": "Hanyu Liu"}, {"authorId": "2313588989", "name": "Boyang Zhao"}, {"authorId": "2059015659", "name": "Qi Shen"}, {"authorId": "2313359513", "name": "Mingzhe Li"}, {"authorId": "2296096895", "name": "Ningfeng Que"}, {"authorId": "2313464590", "name": "Mingke Yan"}, {"authorId": "1759388", "name": "Junchang Xin"}]}
{"paperId": "554ebc10e83e86b7b0a272c04f714519de7cec2c", "url": "https://www.semanticscholar.org/paper/554ebc10e83e86b7b0a272c04f714519de7cec2c", "title": "Handle Dense Labeling in Human Activity Recognition Using Self Attention and BiLSTM", "abstract": "Dense labeling, which annotates an activity label for each data sample in the segment, is a common approach to handle the problem of multi-class windows in wearable sensor-based human activity recognition. Recent success in image-based semantic segmentation offers opportunities to solve this problem by using well-known fully convolutional neural networks. However, the long-term dependencies of human activity are often ignored in these works, thus, lead to unstable prediction results. In this study, we address this problem by proposing a hybrid deep learning system that can effectively extract the context information from the sequential sensor data and densely predict the activity for each data sample. The system is constructed from two main components: 1) a transformer encoder with multi-head self-attention modules that capture the relationship between data samples and extract the salient features from long sequential data, 2) a bidirectional long short-term memory (BiLSTM) maintains the long-term temporal information in human activity. Our experiments on the UCI HAPT public dataset indicate that the proposed hybrid model achieves an accuracy of 93.41%, which is 2% higher compared to other state-of-the-art image-based dense labeling HAR models.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCE59016.2024.10444332?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCE59016.2024.10444332, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2286731302", "name": "Nguyen Thi Hoai Thu"}, {"authorId": "2286715517", "name": "Dong Seog Han"}]}
{"paperId": "f846995c2d6291e1b49b2f5cbc17a715471c5c16", "url": "https://www.semanticscholar.org/paper/f846995c2d6291e1b49b2f5cbc17a715471c5c16", "title": "A human activity recognition method using wearable sensors based on convtransformer model", "abstract": null, "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This paper's abstract has been elided by the publisher. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s12530-022-09480-y?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s12530-022-09480-y, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2156121077", "name": "Zhanpeng Zhang"}, {"authorId": "2200086460", "name": "Wenting Wang"}, {"authorId": "2064101476", "name": "Aimin An"}, {"authorId": "2200047410", "name": "Yuwei Qin"}, {"authorId": "2217762505", "name": "Fazhi Yang"}]}
{"paperId": "7fb675cfaae95dc9d44e1eb4a0ab914072861c92", "url": "https://www.semanticscholar.org/paper/7fb675cfaae95dc9d44e1eb4a0ab914072861c92", "title": "Exploiting Spatial and Temporal Features for Deep Learning Based Human Activity Recognition", "abstract": "Human activity recognition using inertial sensors has gained significant popularity and widespread adoption in various fields, while deep learning has emerged as the dominant approach, playing a pivotal role in enhancing performance. Nevertheless, existing algorithms often neglect the heterogeneity of sensors and fail to effectively extract contextual features from long-term time series data, resulting in low accuracy in activity recognition, especially for complex activities. This paper proposes a novel method called FUsion Transformer hUman activity REcognition(FUTURE). FUTURE exploits the feature fusion mechanism and designs a multi-scaled DenseNet to extract the spatial features so that the relationship between heterogeneous sensors can be captured. Furthermore, a customized multi-head attention model with less computational complexity is employed in FUTURE to capture global dependencies within the sensor data. Experimental results on multiple datasets validate that FUTURE achieves an average recognition accuracy of 95% for complex activities and the evaluation against the state-of-the-art demonstrates the superior performance of the FUTURE model in accurately classifying complex activities.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICPADS60453.2023.00294?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICPADS60453.2023.00294, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2293895025", "name": "Wenying Cao"}, {"authorId": "2293640471", "name": "Gaotao Shi"}, {"authorId": "2293661323", "name": "Tieguan Zhang"}]}
{"paperId": "5b5e68bca20f903df6295f5cc17d4405bb9b8742", "url": "https://www.semanticscholar.org/paper/5b5e68bca20f903df6295f5cc17d4405bb9b8742", "title": "Cross-Person Human Activity Recognition Method Based on the HARG Model", "abstract": "In recent years, Sensor-based human activity recognition technology has found widespread applications in various fields. Recently, Transformer and its variant models, further improving the effectiveness of activity recognition models. However, almost all established models assume that the training and test data maintain data distribution consistency. In practical applications, due to differences in body types, activity styles, and habits, test data distribution changes, leading to a sharp drop in model recognition performance. In this paper, we integrate the Domain-Invariant and the Domain-Specific Feature Module, proposing the Deep Adaptive Domain Feature Module that focuses on deep-level domain features. This is a Domain Generalization-based representation learning that can effectively improve the model\u2019s generalization performance. Specifically, we use Transformer and CNN as the backbone networks, adopt a novel parallelized network structure, proposed the Human Activity Recognition Generalization (HARG) cross-Person human activity recognition model. We systematically evaluate the proposed model on UCI-HAR and Opportunity public datasets, the experiments show that the HARG model has an absolute advantage in cross-domain activity recognition, outperforming current models in recognition performance.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCBD-AI62252.2023.00050?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCBD-AI62252.2023.00050, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2305892035", "name": "Xinyang Zhang"}, {"authorId": "2305887222", "name": "Peng Xin"}, {"authorId": "2307175945", "name": "Jing Zhang"}, {"authorId": "2306056154", "name": "Miao Liu"}, {"authorId": "2305790968", "name": "Hengyi Yue"}, {"authorId": "2305767536", "name": "Minghui Hou"}]}
{"paperId": "38ee117a823fc5963e5d44406c8b89194804c963", "url": "https://www.semanticscholar.org/paper/38ee117a823fc5963e5d44406c8b89194804c963", "title": "A Hybrid Transformer Framework for Efficient Activity Recognition Using Consumer Electronics", "abstract": "In the field of research on wireless visual sensor networks, human activity recognition (HAR) using consumer electronics is now an emerging research area in both the academic and industrial sectors, with a diverse range of applications. However, the implementation of HAR through computer vision methods is highly challenging on consumer electronic devices, due to their limited computational capabilities. This means that mainstream approaches in which computationally complex contextual networks and variants of recurrent neural networks are used to learn long-range spatiotemporal dependencies have achieved limited performance. To address these challenges, this paper presents an efficient framework for robust HAR for consumer electronics devices, which is divided into two main stages. In the first stage, convolutional features from the multiply_17 layer of a lightweight MobileNetV3 are employed to balance the computational complexity and extract the most salient contextual features ( $7\\times 7\\times 576\\times 30$ ) from each video. In the second stage, a sequential residual transformer network (SRTN) is designed in a residual fashion to effectively learn the long-range temporal dependencies across multiple video frames. The temporal multi-head self-attention module and residual strategy of the SRTN enable the proposed method to discard non-relevant features and to optimise the spatiotemporal feature vector for efficient HAR. The performance of the proposed model is evaluated on three challenging HAR datasets, and is found to yield high levels of accuracy of 76.1428%, 96.6399%, and 97.3130% on the HMDB51, UCF101, and UCF50 datasets, respectively, outperforming a state-of-the-art method for HAR.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TCE.2024.3373824?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TCE.2024.3373824, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2276866551", "name": "Altaf Hussain"}, {"authorId": "2268298130", "name": "Samee Ullah Khan"}, {"authorId": "2023677572", "name": "Noman Khan"}, {"authorId": "150203713", "name": "Mohammed Wasim Bhatt"}, {"authorId": "2071968440", "name": "A. Farouk"}, {"authorId": "2290812806", "name": "Jyoti Bhola"}, {"authorId": "2268274265", "name": "Sung Wook Baik"}]}
{"paperId": "cb7adc3fddcceaef5bee9cb2ad08ce4998bbd0b6", "url": "https://www.semanticscholar.org/paper/cb7adc3fddcceaef5bee9cb2ad08ce4998bbd0b6", "title": "Pedestrian Navigation Activity Recognition Based on Segmentation Transformer", "abstract": "In the context of the Internet of Things, utilizing the inherent inertial sensors in smartphones for human activity recognition (HAR) has garnered considerable attention owing to its wide-ranging applications. However, prevailing HAR approaches primarily treat activity identification as a single-label classification task, focusing solely on discerning pedestrian motion modes or device usage modes, while disregarding their interrelatedness. Additionally, HAR methods employing sliding windows encounter challenges associated with the multiclass window problem, wherein certain sample labels differ from the label assigned to the window. This article aims to address these issues. This article presents a novel approach for simultaneously recognizing pedestrian motion and device usage modes by utilizing the segmentation Transformer. The proposed joint recognition framework effectively annotates sensor data at each timestamp and achieves dense prediction of time-series data through the encoding and decoding of the annotated data. To optimize the utilization of information extracted from each Transformer layer, a global up-sampling decoder based on the pyramid attention module is introduced, enabling dense decoding of features obtained from each Transformer layer. We performed experiments on two publicly available data sets to comprehensively assess the effectiveness of the proposed methodology. The results demonstrate that our approach achieves an accuracy of 99.79% and a weighted F-score of 99.77%, surpassing the performance of existing state-of-the-art methods. Furthermore, we constructed heterogeneous data sets to validate the robustness of our method. The extensive experimental findings indicate that the joint recognition framework effectively uncovers the inherent correlations between pedestrian motion and device usage modes, leading to enhanced accuracy in recognition and addressing the challenges posed by the multiclass window problem.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JIOT.2024.3394050?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JIOT.2024.3394050, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2188127932", "name": "Quanze Wang"}, {"authorId": "2299553770", "name": "Zhi Tao"}, {"authorId": "2299629755", "name": "Jiahui Ning"}, {"authorId": "2192411361", "name": "Zhuqing Jiang"}, {"authorId": "2299939493", "name": "Liangliang Guo"}, {"authorId": "2110564481", "name": "Haiyong Luo"}, {"authorId": "2299739102", "name": "Haiying Wang"}, {"authorId": "2254300024", "name": "Aidong Men"}, {"authorId": "2299776325", "name": "Xiaofei Cheng"}, {"authorId": "2276572845", "name": "Zhang Zhang"}]}
{"paperId": "9163748f159a668867bfc2eeec1744d98a69ace3", "url": "https://www.semanticscholar.org/paper/9163748f159a668867bfc2eeec1744d98a69ace3", "title": "Large Receptive Field Attention: An Innovation in Decomposing Large-Kernel Convolution for Sensor-Based Activity Recognition", "abstract": "Sensor-based human activity recognition (HAR) has become an important task in various application domains. However, existing HAR practices such as convolutional networks and recurrent architectures can result in information loss when considering the temporal and sensor modality dimensions separately. In this article, we propose a shallow large receptive field (LRF) attention that addresses this issue by extracting both temporal-wise and modality-wise information for sensor-based HAR scenarios. Our proposed LRF architecture decomposes a large-kernel convolution into three cascaded submodules, including a local depth-wise convolution across different sensor modalities, a long-range depth-wise dilation convolution along temporal sequences, and a ${1} \\times {1}$ plain convolution. We further reconstruct it in a visual transformer (ViT)-like hierarchical style. We validate the proposed LRF architecture on three commonly used HAR datasets as well as a weakly labeled dataset that involves multimodality sensing data from smartphones or wearable sensors. Our experiments show that our proposed method outperforms several state-of-the-art (SOTA) benchmarks, achieving the accuracy of 97.35% in UCI-HAR, 98.88% in WISDM, 97.26% in USC-HAD, 96.77% in weakly labeled, and 91.15% in KU-HAR datasets with a similar number of parameters.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JSEN.2024.3364187?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JSEN.2024.3364187, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "52492311", "name": "Qi Teng"}, {"authorId": "2115420932", "name": "Yin Tang"}, {"authorId": "2204666348", "name": "Guangwei Hu"}]}
{"paperId": "a4cbe1e56d1248a3b7d797d44a0d787dfda32992", "url": "https://www.semanticscholar.org/paper/a4cbe1e56d1248a3b7d797d44a0d787dfda32992", "title": "Sensor Data Representation with Transformer-Based Contrastive Learning for Human Action Recognition and Detection", "abstract": "Feature extraction is an important process in human activity recognition (HAR) with wearable sensors. Recent studies have shown that learned features are more effective than manually engineered features in related fields. However, the scarcity and expensiveness of labeled data are limiting the development of sensor data representation learning. Our work focuses on this issue and introduces a self-supervised learning method that uses unlabeled data to improve the quality of learned sensor representations. We hypothesize that unlabeled wearable sensor data in human activities have long-term and short-term temporal contextual correlations and exploit such correlations with Transformer and Contrastive Predictive Coding (CPC) framework. The learned representation is evaluated on human activity recognition and detection tasks in real-life scenarios. The experiments show that our method outperforms previous state-of-the-art methods on MotionSense and MobiAct datasets on the HAR task and gets a remarkable performance on the EVARS dataset on the action detection task.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.23919/EUSIPCO58844.2023.10289883?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.23919/EUSIPCO58844.2023.10289883, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2264000393", "name": "Lei Yang"}, {"authorId": "2264589234", "name": "Yuzhe Hao"}, {"authorId": "2264277619", "name": "Koichi Shinoda"}]}
{"paperId": "01dfd858b7cc394eef251d055445e823e8eb05a4", "url": "https://www.semanticscholar.org/paper/01dfd858b7cc394eef251d055445e823e8eb05a4", "title": "Using a Semi-supervised Learning Model for Recognition of Human Daily Activities from Wearable Sensor Data", "abstract": "The application of Machine Learning (ML) and Artificial Intelligence (AI) is growing, and also becoming more important as the aging population increases. Smart support systems for distinguish Activities of Daily Living (ADL) can help the elders live more independently and safely. Many machine learning methods have been proposed for Human Activity Recognition (HAR), including complex networks containing convolutional, recurrent, and attentional layers. This study explores the application of ML techniques in ADL classification, leveraging wearable devices' time-series data capturing various parameters such as acceleration. The acceleration data obtained from sensors is so huge that it is difficult and expensive to accurately label every sample collected, so this study applies the Semi-supervised Learning model to unlabeled samples. Long Short-Term Memory (LSTM) has always been used for time series data such as acceleration, and recently, the Transformer model has emerged in many applications such as Natural Language Processing (NLP) or creating ChatGPT. In this study we proposed ADL classification method using the Self-Attention Transformer block and the Recurrent LSTM block and evaluated their results. After comparison, the model built with LSTM block gives better results than the model built with Transformer block.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.29099/ijair.v8i1.1146?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.29099/ijair.v8i1.1146, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2216601840", "name": "T. Nguyen"}]}
{"paperId": "b5ac28def8f3ca49211bdbce97454e441345a41c", "url": "https://www.semanticscholar.org/paper/b5ac28def8f3ca49211bdbce97454e441345a41c", "title": "Human behavior recognition based on sparse transformer with channel attention mechanism", "abstract": "Human activity recognition (HAR) has recently become a popular research field in the wearable sensor technology scene. By analyzing the human behavior data, some disease risks or potential health issues can be detected, and patients\u2019 rehabilitation progress can be evaluated. With the excellent performance of Transformer in natural language processing and visual tasks, researchers have begun to focus on its application in time series. The Transformer model models long-term dependencies between sequences through self-attention mechanisms, capturing contextual information over extended periods. In this paper, we propose a hybrid model based on the channel attention mechanism and Transformer model to improve the feature representation ability of sensor-based HAR tasks. Extensive experiments were conducted on three public HAR datasets, and the results show that our network achieved accuracies of 98.10%, 97.21%, and 98.82% on the HARTH, PAMAP2, and UCI-HAR datasets, respectively, The overall performance is at the level of the most advanced methods.", "openAccessPdf": {"url": "https://www.frontiersin.org/articles/10.3389/fphys.2023.1239453/pdf?isPublishedV2=False", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10653302, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2265331662", "name": "Keyan Cao"}, {"authorId": "2265367719", "name": "Mingrui Wang"}]}
{"paperId": "928910dec3a97a9810ed9cc97388c3ef84701138", "url": "https://www.semanticscholar.org/paper/928910dec3a97a9810ed9cc97388c3ef84701138", "title": "ST-PCT: Spatial\u2013Temporal Point Cloud Transformer for Sensing Activity Based on mmWave", "abstract": "The millimeter-wave (mmWave) spectrum has become a core of wireless communication, which has the advantages of richer spectrum resources, larger communication bandwidth, and smaller spectrum interference. Human activity recognition (HAR) by mmWave radar based on point cloud attracts significant attention due to its nature of privacy-preserving, which is an important task of realizing integrated sensing and communication (ISAC). This article proposes a framework of spatial\u2013temporal point cloud transformer (ST-PCT) to realize high precision of HAR, based on sequential point cloud after preprocessing from mmWave radar without voxelization. In ST-PCT, it consists of four enhanced components: 1) a framewise spatial neighbor embedding module to extract the local feature; 2) a temporal and spatial attention mechanism module to find connections within and across frames; 3) an optimized attention mechanism to improve the efficiency of feature extraction; and 4) a sensor fusion module with more motion information to improve the difference between activities. We experimentally evaluate the efficiency of our framework compared with several approaches based on the voxelization or point cloud directly. The experimental results have demonstrated that the proposed ST-PCT network greatly outperforms the other approaches in terms of overall accuracy (oAcc), achieving 99.06% and 99.44%, respectively, on two data sets.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JIOT.2023.3329236?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JIOT.2023.3329236, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2264357840", "name": "Liyu Kang"}, {"authorId": "2144233473", "name": "Zan Li"}, {"authorId": "2142208108", "name": "Xiaohui Zhao"}, {"authorId": "2232760", "name": "Zhongliang Zhao"}, {"authorId": "2174067352", "name": "Torsten Braun"}]}
{"paperId": "861c3e765c278071f28c2a4fa1e74a28a50fcfbc", "url": "https://www.semanticscholar.org/paper/861c3e765c278071f28c2a4fa1e74a28a50fcfbc", "title": "WiFi-TCN: Temporal Convolution for Human Interaction Recognition Based on WiFi Signal", "abstract": "The quest for efficient and non-intrusive human activity recognition (HAR) in indoor environments has led to the burgeoning field of WiFi-based HAR. This method promises applications from healthcare monitoring to elderly care due to its cost-effectiveness and ease of deployment compared to traditional sensor-based systems. However, WiFi-based HAR faces significant challenges in maintaining performance across diverse environments and subjects, largely due to WiFi signal variability. Addressing this issue necessitates training models on extensive datasets. Recent studies have utilized conventional models, including Convolutional Neural Networks (CNNs), and sequence-to-sequence (Seq2Seq) models such as LSTM, GRU, or Transformer. Despite their precision, these models are computationally intensive and require more training data. To tackle these limitations, we propose a novel approach that leverages a Temporal Convolutional Network with Augmentations and Attention, referred to as TCN-AA. This model enhances computational efficiency and accuracy in the face of dataset variability by combining temporal convolutional layers with data augmentation strategies and an attention mechanism to focus on critical features. Our method is computationally efficient and significantly improves accuracy, even with a threefold increase in data size through augmentation techniques. Experiments on a public dataset indicate our approach outperforms state-of-the-art methods, achieving 99.42% accuracy. This work represents a significant step forward in the practical application of WiFi-based HAR, paving the way for broader adoption in critical areas like healthcare and security.", "openAccessPdf": {"url": "https://doi.org/10.1109/access.2024.3428550", "status": "GOLD", "license": "CCBYNCND", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2305.18211, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2224123732", "name": "Chih-Yang Lin"}, {"authorId": "2321659148", "name": "Chia-Yu Lin"}, {"authorId": "2321656146", "name": "Yu-Tso Liu"}, {"authorId": "2321686515", "name": "Yi-Wei Chen"}, {"authorId": "2249007959", "name": "Timothy K. Shih"}]}
{"paperId": "d6eac46852401113b7584b13eec4188527b1bd27", "url": "https://www.semanticscholar.org/paper/d6eac46852401113b7584b13eec4188527b1bd27", "title": "A Survey of Machine Learning and Meta-heuristics Approaches for Sensor-based Human Activity Recognition Systems", "abstract": null, "openAccessPdf": {"url": "", "status": null, "license": null}, "publicationTypes": ["JournalArticle", "Review"], "authors": [{"authorId": "2147061092", "name": "Anindita Saha"}, {"authorId": "2128989430", "name": "Sajan Rajak"}, {"authorId": "48255762", "name": "Jayita Saha"}, {"authorId": "2157899", "name": "C. Chowdhury"}]}
{"paperId": "10c60da5a0793d9cc6f8ebe1bfbb971a5ebb61a2", "url": "https://www.semanticscholar.org/paper/10c60da5a0793d9cc6f8ebe1bfbb971a5ebb61a2", "title": "MLCNNwav: Multilevel Convolutional Neural Network With Wavelet Transformations for Sensor-Based Human Activity Recognition", "abstract": "Human activity recognition (HAR) is a rapidly growing field of research that aims to automatically identify and classify human motions and activities from different tracking devices, such as cameras and sensors. One of the most widely used sensor modalities for HAR is the smartphone, which has various sensors, such as gyroscopes, accelerometers, and GPS, that can provide rich information about a person\u2019s movements and actions. HAR applications are essential for the Internet of Things (IoT) and smart home industries. We used the recent advances in deep learning techniques to develop a new HAR model for wearable sensors. The proposed model, MLCNNwav, relies on residual convolutional neural networks and 1-D trainable discrete wavelet transform. The multilevel CNN is designed to capture global features, whereas the wavelet transformation enhances the representation and generalization by learning activity-related features. Several deep learning approaches are compared to assess the superiority of the developed model. Four public benchmarks HAR data sets were used for the evaluation. The outcomes confirmed that the developed MLCNNwav recorded high-accuracy rates on all data sets.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JIOT.2023.3286378?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JIOT.2023.3286378, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "7286047", "name": "Abdelghani Dahou"}, {"authorId": "2179576117", "name": "M. A. Al-qaness"}, {"authorId": "2196344868", "name": "Mohamed E. Abd Elaziz"}, {"authorId": "145338451", "name": "A. Helmi"}]}
{"paperId": "dfe96b0ddb90e092d3dfdee36367705d527e080c", "url": "https://www.semanticscholar.org/paper/dfe96b0ddb90e092d3dfdee36367705d527e080c", "title": "Wireless body area sensor networks based human activity recognition using deep learning", "abstract": "In the healthcare sector, the health status and biological, and physical activity of the patient are monitored among different sensors that collect the required information about these activities using Wireless body area network (WBAN) architecture. Sensor-based human activity recognition (HAR), which offers remarkable qualities of ease and privacy, has drawn increasing attention from researchers with the growth of the Internet of Things (IoT) and wearable technology. Deep learning has the ability to extract high-dimensional information automatically, making end-to-end learning. The most significant obstacles to computer vision, particularly convolutional neural networks (CNNs), are the effect of the environment background, camera shielding, and other variables. This paper aims to propose and develop a new HAR system in WBAN dependence on the Gramian angular field (GAF) and DenseNet. Once the necessary signals are obtained, the input signals undergo pre-processing through artifact removal and median filtering. In the initial stage, the time series data captured by the sensors undergoes a conversion process, transforming it into 2-dimensional images by using the GAF algorithm. Then, DenseNet automatically makes the processes and integrates the data collected from diverse sensors. The experiment results show that the proposed method achieves the best outcomes in which it achieves 97.83% accuracy, 97.83% F-measure, and 97.64 Matthews correlation coefficient (MCC).", "openAccessPdf": {"url": "https://www.nature.com/articles/s41598-024-53069-1.pdf", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10834495, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2282263080", "name": "Ehab El-Adawi"}, {"authorId": "9116503", "name": "Ehab Essa"}, {"authorId": "2098338129", "name": "Mohamed Handosa"}, {"authorId": "2257220613", "name": "Samir Elmougy"}]}
{"paperId": "73f55e8877db271dd2881678e386b8b1b329912b", "url": "https://www.semanticscholar.org/paper/73f55e8877db271dd2881678e386b8b1b329912b", "title": "Large Language Models for Wearable Sensor-Based Human Activity Recognition, Health Monitoring, and Behavioral Modeling: A Survey of Early Trends, Datasets, and Challenges", "abstract": "The proliferation of wearable technology enables the generation of vast amounts of sensor data, offering significant opportunities for advancements in health monitoring, activity recognition, and personalized medicine. However, the complexity and volume of these data present substantial challenges in data modeling and analysis, which have been addressed with approaches spanning time series modeling to deep learning techniques. The latest frontier in this domain is the adoption of large language models (LLMs), such as GPT-4 and Llama, for data analysis, modeling, understanding, and human behavior monitoring through the lens of wearable sensor data. This survey explores the current trends and challenges in applying LLMs for sensor-based human activity recognition and behavior modeling. We discuss the nature of wearable sensor data, the capabilities and limitations of LLMs in modeling them, and their integration with traditional machine learning techniques. We also identify key challenges, including data quality, computational requirements, interpretability, and privacy concerns. By examining case studies and successful applications, we highlight the potential of LLMs in enhancing the analysis and interpretation of wearable sensor data. Finally, we propose future directions for research, emphasizing the need for improved preprocessing techniques, more efficient and scalable models, and interdisciplinary collaboration. This survey aims to provide a comprehensive overview of the intersection between wearable sensor data and LLMs, offering insights into the current state and future prospects of this emerging field.", "openAccessPdf": {"url": "https://doi.org/10.3390/s24155045", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.07196, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Review", "JournalArticle"], "authors": [{"authorId": "48898287", "name": "Emilio Ferrara"}]}
{"paperId": "c35419901dd3683c62f238adf1f9c7db8cb8b8d6", "url": "https://www.semanticscholar.org/paper/c35419901dd3683c62f238adf1f9c7db8cb8b8d6", "title": "CapMatch: Semi-Supervised Contrastive Transformer Capsule With Feature-Based Knowledge Distillation for Human Activity Recognition", "abstract": "This article proposes a semi-supervised contrastive capsule transformer method with feature-based knowledge distillation (KD) that simplifies the existing semisupervised learning (SSL) techniques for wearable human activity recognition (HAR), called CapMatch. CapMatch gracefully hybridizes supervised learning and unsupervised learning to extract rich representations from input data. In unsupervised learning, CapMatch leverages the pseudolabeling, contrastive learning (CL), and feature-based KD techniques to construct similarity learning on lower and higher level semantic information extracted from two augmentation versions of the data, \u201cweak\u201d and \u201ctimecut,\u201d to recognize the relationships among the obtained features of classes in the unlabeled data. CapMatch combines the outputs of the weak- and timecut-augmented models to form pseudolabeling and thus CL. Meanwhile, CapMatch uses the feature-based KD to transfer knowledge from the intermediate layers of the weak-augmented model to those of the timecut-augmented model. To effectively capture both local and global patterns of HAR data, we design a capsule transformer network consisting of four capsule-based transformer blocks and one routing layer. Experimental results show that compared with a number of state-of-the-art semi-supervised and supervised algorithms, the proposed CapMatch achieves decent performance on three commonly used HAR datasets, namely, HAPT, WISDM, and UCI_HAR. With only 10% of data labeled, CapMatch achieves <inline-formula> <tex-math notation=\"LaTeX\">$F_{1}$ </tex-math></inline-formula> values of higher than 85.00% on these datasets, outperforming 14 semi-supervised algorithms. When the proportion of labeled data reaches 30%, CapMatch obtains <inline-formula> <tex-math notation=\"LaTeX\">$F_{1}$ </tex-math></inline-formula> values of no lower than 88.00% on the datasets above, which is better than several classical supervised algorithms, e.g., decision tree and <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>-nearest neighbor (KNN).", "openAccessPdf": {"url": "https://nottingham-repository.worktribe.com/preview/29031919/TNNLS23-CapMatch.pdf", "status": "GREEN", "license": "other-oa", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNNLS.2023.3344294?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNNLS.2023.3344294, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "50479843", "name": "Zhiwen Xiao"}, {"authorId": "2199262489", "name": "Huagang Tong"}, {"authorId": "145036587", "name": "Rong Qu"}, {"authorId": "2258418147", "name": "Huanlai Xing"}, {"authorId": "2962874", "name": "Shouxi Luo"}, {"authorId": "2276745209", "name": "Zonghai Zhu"}, {"authorId": "10733817", "name": "Fuhong Song"}, {"authorId": "2261737428", "name": "Li Feng"}]}
{"paperId": "3b427c8d3258968b9ac5eaf846d99ac027de9a76", "url": "https://www.semanticscholar.org/paper/3b427c8d3258968b9ac5eaf846d99ac027de9a76", "title": "A human activity recognition method based on Vision Transformer", "abstract": "Human activity recognition has a wide range of applications in various fields, such as video surveillance, virtual reality and human\u2013computer intelligent interaction. It has emerged as a significant research area in computer vision. GCN (Graph Convolutional networks) have recently been widely used in these fields and have made great performance. However, there are still some challenges including over-smoothing problem caused by stack graph convolutions and deficient semantics correlation to capture the large movements between time sequences. Vision Transformer (ViT) is utilized in many 2D and 3D image fields and has surprised results. In our work, we propose a novel human activity recognition method based on ViT (HAR-ViT). We integrate enhanced AGCL (eAGCL) in 2s-AGCN to ViT to make it process spatio-temporal data (3D skeleton) and make full use of spatial features. The position encoder module orders the non-sequenced information while the transformer encoder efficiently compresses sequence data features to enhance calculation speed. Human activity recognition is accomplished through multi-layer perceptron (MLP) classifier. Experimental results demonstrate that the proposed method achieves SOTA performance on three extensively used datasets, NTU RGB+D 60, NTU RGB+D 120 and Kinetics-Skeleton 400.", "openAccessPdf": {"url": "https://www.nature.com/articles/s41598-024-65850-3.pdf", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11222487, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2367119", "name": "Huiyan Han"}, {"authorId": "47316010", "name": "H. Zeng"}, {"authorId": "2982984", "name": "Liqun Kuang"}, {"authorId": "2290161646", "name": "Xie Han"}, {"authorId": "2309801356", "name": "Hongxin Xue"}]}
{"paperId": "f1057758c7ca7fe2babeea4908c281be9d1075c4", "url": "https://www.semanticscholar.org/paper/f1057758c7ca7fe2babeea4908c281be9d1075c4", "title": "IMUGPT 2.0: Language-Based Cross Modality Transfer for Sensor-Based Human Activity Recognition", "abstract": "One of the primary challenges in the field of human activity recognition (HAR) is the lack of large labeled datasets. This hinders the development of robust and generalizable models. Recently, cross modality transfer approaches have been explored that can alleviate the problem of data scarcity. These approaches convert existing datasets from a source modality, such as video, to a target modality, such as inertial measurement units (IMUs). With the emergence of generative AI models such as large language models (LLMs) and text-driven motion synthesis models, language has become a promising source data modality as well - as shown in proof of concepts such as IMUGPT. In this work, we conduct a large-scale evaluation of language-based cross modality transfer to determine their effectiveness for HAR. Based on this study, we introduce two new extensions for IMUGPT that enhance its use for practical HAR application scenarios: a motion filter capable of filtering out irrelevant motion sequences to ensure the relevance of the generated virtual IMU data, and a set of metrics that measure the diversity of the generated data facilitating the determination of when to stop generating virtual IMU data for both effective and efficient processing. We demonstrate that our diversity metrics can reduce the effort needed for the generation of virtual IMU data by at least 50%, which opens up IMUGPT for practical use cases beyond a mere proof of concept.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2402.01049, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2078695879", "name": "Zi-Jian Leng"}, {"authorId": "2143071581", "name": "Amitrajit Bhattacharjee"}, {"authorId": "2282472428", "name": "Hrudhai Rajasekhar"}, {"authorId": "2282502540", "name": "Lizhe Zhang"}, {"authorId": "2282471439", "name": "Elizabeth Bruda"}, {"authorId": "2253816074", "name": "Hyeokhyen Kwon"}, {"authorId": "2261945280", "name": "Thomas Pl\u00f6tz"}]}
{"paperId": "c3ce9890321ce353e0376078356a9b9932e6be79", "url": "https://www.semanticscholar.org/paper/c3ce9890321ce353e0376078356a9b9932e6be79", "title": "Feature Fusion for Human Activity Recognition using Parameter-Optimized Multi-Stage Graph Convolutional Network and Transformer Models", "abstract": "Human activity recognition is a crucial area of research that involves understanding human movements using computer and machine vision technology. Deep learning has emerged as a powerful tool for this task, with models such as Convolutional Neural Networks (CNNs) and Transformers being employed to capture various aspects of human motion. One of the key contributions of this work is the demonstration of the effectiveness of feature fusion in improving human activity recognition accuracy, which has important implications for the development of more accurate and robust activity recognition systems. This approach addresses a limitation in the field, where the performance of existing models is often limited by their inability to capture both spatial and temporal features effectively. This work presents an approach for human activity recognition using sensory data extracted from four distinct datasets: HuGaDB, PKU-MMD, LARa, and TUG. Two models, the Parameter-Optimized Multi-Stage Graph Convolutional Network (PO-MS-GCN) and a Transformer, were trained and evaluated on each dataset to calculate accuracy and F1-score. Subsequently, the features from the last layer of each model were combined and fed into a classifier. The findings prove that PO MS-GCN outperforms state-of-the-art models in human activity recognition. Specifically, HuGaDB achieved an accuracy of 92.7% and f1-score of 95.2%, TUG achieved an accuracy of 93.2% and f1-score of 98.3%, while LARa and PKU-MMD achieved lower accuracies of 64.31% and 69%, respectively, with corresponding f1-scores of 40.63% and 48.16%. Moreover, feature fusion exceeded the PO-MS-GCN\u2019s results in PKU-MMD, LARa, and TUG datasets.", "openAccessPdf": {"url": "https://arxiv.org/pdf/2406.16638", "status": "GREEN", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2406.16638, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2306435986", "name": "Mohammad Belal"}, {"authorId": "2268284723", "name": "Taimur Hassan"}, {"authorId": "2169439781", "name": "A. Ahmed"}, {"authorId": "2219926728", "name": "Ahmad Aljarah"}, {"authorId": "2306372244", "name": "Nael Alsheikh"}, {"authorId": "2311498042", "name": "Irfan Hussain"}]}
{"paperId": "ec0c9af4d9bc9ada0c1aba1025a5231bb55eb9e1", "url": "https://www.semanticscholar.org/paper/ec0c9af4d9bc9ada0c1aba1025a5231bb55eb9e1", "title": "FML-Vit: A Lightweight Vision Transformer Algorithm for Human Activity Recognition Using FMCW Radar", "abstract": "In recent years, human activity recognition (HAR) using frequency module continuous wave (FMCW) radar is an effective tool that has been widely used in the fields of healthcare, smart driving, and smart living due to its convenience, inexpensiveness, and accuracy. Past studies have mainly investigated the improvement of the accuracy of HAR models while neglecting the deployment of the models. Therefore, we propose a model named FMCW lightweight vision transformer (FML-Vit) for HAR, primarily consisting of the FML-Vit block and FML-Vit subsample modules. The FML-Vit block, by incorporating a cascaded linear self-attention mechanism in place of the traditional multi-head attention mechanism, can transform the time complexity from ${O}\\text {(} {k}^{{2}} \\text {)}$ to ${O}\\text {(}{k}\\text {)}$ . The FML-Vit subsampling modules perform dimension reduction and feature reallocation, while the context broadcasting (CB) module is used to reduce the density in the original attention maps, thereby increasing both the capacity and generalizability of the ViT. The proposed algorithm is compared with nine different state-of-the-art methods on self-datasets and open-source datasets. The results demonstrate that FML-Vit outperforms other current lightweight networks with the fastest inference.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/jsen.2024.3473890?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/jsen.2024.3473890, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2318388312", "name": "Minhan Ding"}, {"authorId": "2308776718", "name": "Guangxin Dongye"}, {"authorId": "2319233072", "name": "Ping Lv"}, {"authorId": "46304470", "name": "Yipeng Ding"}]}
{"paperId": "28efec131d1304f68877c45dc2688d31aef24d0c", "url": "https://www.semanticscholar.org/paper/28efec131d1304f68877c45dc2688d31aef24d0c", "title": "CNN-GRU-Transformer Human Activity Recognition Model Based on Feature Fusion", "abstract": "In recent years, human activity recognition technology has received great attention in various fields. The focus of this technology is to use wearable sensors connected to various locations on the human body to identify and classify human activity data. At present, many recognition algorithms can already recognize simple human activities. And achieved good results. The recognition effect of complex human activities collected by multiple sensors is poor. Therefore, this article proposes a CNN-GRU-Transformer human activity recognition model based on feature fusion. Fusion of data features from multiple sensors. Further explore the temporal dependence of the fused features. GRU can extract short-term temporal information from data. Transformers can effectively extract long-term dependencies from data. The combination of the two can effectively capture global features in the data. Improve the generalization of the model. The model was tested on the MSHA dataset and OCA dataset. The recognition accuracy reached 98% and 96% respectively. And compare and analyze with some existing models. This proves the superiority of the model proposed in this article.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICFTIC64248.2024.10913436?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICFTIC64248.2024.10913436, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2350084190", "name": "Li Wang"}, {"authorId": "2350068937", "name": "Zhilong Zhang"}, {"authorId": "2350179879", "name": "Likun Wei"}, {"authorId": "2303617204", "name": "Yuqi Zhou"}]}
{"paperId": "50de46c347645a1bdabd3f6fd342db3b2cd5e768", "url": "https://www.semanticscholar.org/paper/50de46c347645a1bdabd3f6fd342db3b2cd5e768", "title": "Sparse Millimeter-wave Radar Point Clouds based Transformer for Human Activity Recognition", "abstract": "Compared to visual and wearable sensors, activity recognition based on millimeter-wave radar offers a better experience in terms of privacy and comfort. However, the point clouds generated by the millimeter-wave radar are sparse, and existing methods struggle to extract temporal and spatial features from the point clouds. To fully exploit the information in sparse point clouds sequences and accurately capture the spatiotemporal relationships within them, we propose Millimeter-wave radar-based Transformer for human Activity Recognition (MTAR), an innovative approach that achieves accurate human activity recognition by leveraging sparse point clouds as input through Transformers. This method enhances the identification and feature extraction of key channels in point clouds data by introducing PointNet with channel attention mechanisms. Additionally, we employ a dual-branch Transformer architecture, specifically designed to analyze the intrinsic connections within the temporal and spatial dimensions, and further optimize the integration of temporal and spatial features through an adaptive-weighted fusion Transformer, thereby improving the overall performance of the model. Comprehensive evaluations show that with fewer parameters and similar FLOPs, the MTAR outperforms the closest rival by 2.5% on the MM- Fi dataset and by 2.35% on the MMgesture dataset, showcasing its superior generalization performance in experiments with different individuals and environments as well.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/CAC63892.2024.10864729?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/CAC63892.2024.10864729, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": null, "authors": [{"authorId": "2345408048", "name": "Binchao Liu"}, {"authorId": "2291864093", "name": "Jilei Li"}, {"authorId": "2291738683", "name": "Zuoting Song"}, {"authorId": "2291611577", "name": "Yunlong Xia"}, {"authorId": "2345506478", "name": "Ping Li"}, {"authorId": "2291611350", "name": "Qifeng Fan"}]}
{"paperId": "5778c313741449deea596ee3b21c84a3b0d2dfe9", "url": "https://www.semanticscholar.org/paper/5778c313741449deea596ee3b21c84a3b0d2dfe9", "title": "Hybrid Transformer-EfficientNet Model for Robust Human Activity Recognition: The BiTransAct Approach", "abstract": "Human Activity Recognition (HAR) has been employed in a number of applications including sports analytic, healthcare monitoring, surveillance, and human-computer interaction. Despite a decade of research on HAR, existing models still find it challenging under conditions like occlusion, computational efficiency, and capturing long-term temporal dependencies. To address these shortcomings, we present BiTransAct, a novel hybrid model that incorporates EfficientNet-B0 for spatial features extraction as well as Transformer Encoder to obtain the temporal relationships in video data. To evaluate the performance of our proposed model we have employed a video based dataset called SPHAR-Dataset-1.0. This dataset contains 7,759 videos with 14 diverse activities and 421,441 samples. From our experiments its established that BiTransAct consistently excels other deep learning based models like SWIN, EfficientNet, and RegNet in terms of both classification accuracy and precision. Its efficiency in handling large datasets without compromising on performance makes it stronger candidate for real-time HAR tasks. Furthermore, the features like self-attention mechanism and dynamic learning rate make BiTransAct even more robust and avoid overfitting. The results demonstrate that BiTransAct provides a scalable, efficient solution for HAR applications, with particular relevance for real-world scenarios such as video surveillance and healthcare monitoring.", "openAccessPdf": {"url": "https://doi.org/10.1109/access.2024.3506598", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2024.3506598?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2024.3506598, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2005376133", "name": "Aftab Ul Nabi"}, {"authorId": "2238152674", "name": "Jinglun Shi"}, {"authorId": "2335139947", "name": ".. Kamlesh"}, {"authorId": "49107834", "name": "A. Jumani"}, {"authorId": "2335139945", "name": "Jameel Ahmed Bhutto"}]}
{"paperId": "b8065cec2af463890662319079bac18e00e7f0fb", "url": "https://www.semanticscholar.org/paper/b8065cec2af463890662319079bac18e00e7f0fb", "title": "Revolutionizing health monitoring: Integrating transformer models with multi-head attention for precise human activity recognition using wearable devices.", "abstract": "BACKGROUND\nA daily activity routine is vital for overall health and well-being, supporting physical and mental fitness. Consistent physical activity is linked to a multitude of benefits for the body, mind, and emotions, playing a key role in raising a healthy lifestyle. The use of wearable devices has become essential in the realm of health and fitness, facilitating the monitoring of daily activities. While convolutional neural networks (CNN) have proven effective, challenges remain in quickly adapting to a variety of activities.\n\n\nOBJECTIVE\nThis study aimed to develop a model for precise recognition of human activities to revolutionize health monitoring by integrating transformer models with multi-head attention for precise human activity recognition using wearable devices.\n\n\nMETHODS\nThe Human Activity Recognition (HAR) algorithm uses deep learning to classify human activities using spectrogram data. It uses a pretrained convolution neural network (CNN) with a MobileNetV2 model to extract features, a dense residual transformer network (DRTN), and a multi-head multi-level attention architecture (MH-MLA) to capture time-related patterns. The model then blends information from both layers through an adaptive attention mechanism and uses a SoftMax function to provide classification probabilities for various human activities.\n\n\nRESULTS\nThe integrated approach, combining pretrained CNN with transformer models to create a thorough and effective system for recognizing human activities from spectrogram data, outperformed these methods in various datasets - HARTH, KU-HAR, and HuGaDB produced accuracies of 92.81%, 97.98%, and 95.32%, respectively. This suggests that the integration of diverse methodologies yields good results in capturing nuanced human activities across different activities. The comparison analysis showed that the integrated system consistently performs better for dynamic human activity recognition datasets.\n\n\nCONCLUSION\nIn conclusion, maintaining a routine of daily activities is crucial for overall health and well-being. Regular physical activity contributes substantially to a healthy lifestyle, benefiting both the body and the mind. The integration of wearable devices has simplified the monitoring of daily routines. This research introduces an innovative approach to human activity recognition, combining the CNN model with a dense residual transformer network (DRTN) with multi-head multi-level attention (MH-MLA) within the transformer architecture to enhance its capability.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3233/THC-241064?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3233/THC-241064, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "74422867", "name": "Anandhavalli Muniasamy"}]}
{"paperId": "bff860e7b39f16ddb9dd3e2b130a19c2e9682cc2", "url": "https://www.semanticscholar.org/paper/bff860e7b39f16ddb9dd3e2b130a19c2e9682cc2", "title": "A Human Activity Recognition model based on CNN and Transformer", "abstract": "\n This study aims to utilize data from built-in sensors in smartphones for human activity recognition. By analyzing the three-dimensional accelerometer and gyroscope data in user behavior, accurate classification of eight common activity states is achieved, including walking, standing, sitting, squatting, going up stairs, going down stairs, climbing ladders, and descending ladders. To enhance the model\u2019s generalization capability, a method combining Transformer neural networks with one-dimensional Convolutional Neural Networks (CNNs) is employed, along with data sample augmentation. Experimental results demonstrate a significant improvement in recognition accuracy compared to traditional models, indicating the potential for real-time application on smartphones and other devices. This approach provides essential technical support for predictive human-computer interaction on smart devices and holds extensive application prospects.", "openAccessPdf": {"url": "https://doi.org/10.1088/1742-6596/2816/1/012101", "status": "GOLD", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1088/1742-6596/2816/1/012101?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1088/1742-6596/2816/1/012101, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2318613543", "name": "Man Wang"}, {"authorId": "2318144116", "name": "Rutong Liu"}, {"authorId": "2319449544", "name": "Yong Xiong"}]}
{"paperId": "03bb4eefe0fe012870fe058f101cefbe7a9fbb39", "url": "https://www.semanticscholar.org/paper/03bb4eefe0fe012870fe058f101cefbe7a9fbb39", "title": "A multi-channel hybrid deep learning framework for multi-sensor fusion enabled human activity recognition", "abstract": null, "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.aej.2024.01.030?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.aej.2024.01.030, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2287239606", "name": "Lei Zhang"}, {"authorId": "2286997532", "name": "Jingwei Yu"}, {"authorId": "2209825953", "name": "Zhenyu Gao"}, {"authorId": "2248826739", "name": "Qin Ni"}]}
{"paperId": "2b74bcb5242048e088d345ab1f080d448e65e4f9", "url": "https://www.semanticscholar.org/paper/2b74bcb5242048e088d345ab1f080d448e65e4f9", "title": "A Convolutional Transformer for Enhanced NILM in Human Activity Recognition", "abstract": "Monitoring human activities is crucial within Ambient Assisted Living (AAL) contexts, contributing significantly to diagnosis. Data collected from smart meters or home sensors allow the deduction of various Activities of Daily Living (ADL), including eating patterns, sleeping, and routine alterations, providing insights into overall health and well-being. Currently, activity recognition in AAL heavily relies on ambient sensors. Information regarding appliance usage offers valuable insights into health, including immobility, sleep disorders, and activity patterns. In this regard, Non-Intrusive Load Monitoring (NILM) systems represent an interesting alternative as they minimize installation invasiveness. This work proposes an innovative Convolutional Transformer model to enhance the performance of NILM systems based on the sequence-to-point approach, which can be applied to load identification and behavior pattern monitoring. The model has been validated and tested on a widely-used public dataset in the NILM context, and the metrics obtained have been compared with a state-of-the-art NILM algorithm.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/MeMeA60663.2024.10596791?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/MeMeA60663.2024.10596791, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "1409504346", "name": "S. Mari"}, {"authorId": "2767544", "name": "F. Ciancetta"}, {"authorId": "2313861100", "name": "\u00c1lvaro Hern\u00e1ndez"}, {"authorId": "2315323459", "name": "Daniel Pizarro-Perez"}, {"authorId": "2031063539", "name": "Laura de Diego-Ot\u00f3n"}, {"authorId": "2273980600", "name": "V\u00edctor M. Navarro"}]}
{"paperId": "0b45d5937cae7553258fc0818bcfb1848902eb11", "url": "https://www.semanticscholar.org/paper/0b45d5937cae7553258fc0818bcfb1848902eb11", "title": "Leveraging Attention Mechanisms in Vision Transformer for Human Activity Recognition", "abstract": "Due to the emergence of AI, human activity recognition (HAR) domain is now one of the widely explored challenges expanding its necessity in the field of action data analysis, sports data analysis, fall detection, crime activity recognition, and many more. Yet HAR still experiences many challenges due to environmental dependency, different viewpoints, and illumination conditions making handling inter-class variance and intra-class similarity more challenging. As traditional approaches often rely on the spatial feature extractor for spatial context learning and the temporal feature extractor for training on the temporal domain, without the help of the temporal feature extractor, the spatial feature extractor often fails to generalize the model due to dependency or biases on action environmental aspect. Such a problem arises due to the fact that spatial feature extractors are trained to recognize action by learning to associate a particular background with a specific action using spatial correlation. Although debiasing techniques such as debiasing networks, classifiers, and cascading methods were implemented but could not focus on the specific relation on human or object identifier techniques. In such cases the necessity for implementing an effective spatial feature attention for image data or spatio-temporal attention mechanism for video data are often widely unexplored. The model may concentrate on the most pertinent portions of the input data thanks to attention methods. Based on the limitations of previous work we propose a vision transformer leveraging spatial attention mechanism in image data and spatio-temporal attention in video data-based architecture where we have evaluated the model using real-world datasets UCF Sports Action and BAR dataset getting max accuracy of 96.66% and 64.11% outperforming other state-of-the-art methods.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICICT64387.2024.10839708?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICICT64387.2024.10839708, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2341729863", "name": "Abir Hassan"}, {"authorId": "2261736969", "name": "Md Shihab Hossain"}, {"authorId": "2244326158", "name": "Kaushik Deb"}]}
{"paperId": "6477ef37433b0fed0a8b9536abfea948439466ff", "url": "https://www.semanticscholar.org/paper/6477ef37433b0fed0a8b9536abfea948439466ff", "title": "Lightweight Two-Stream Convolution-Augmented Transformer for Multi-Task Human Activity Recognition Using Wi-Fi Sensing", "abstract": "With the rapid growth of smart cities and smart homes, indoor human activity recognition (HAR) has become a critical technology for applications in security, health monitoring, and smart home automation. This paper introduces a lightweight and efficient HAR method based on Channel State Information (CSI) from Wi-Fi signals, utilizing the LTHAT network, a simplified yet powerful model optimized for resource-constrained environments. The proposed approach employs a modified Convolutional Neural Network (CNN) architecture with reduced computational complexity, featuring an adaptive attention mechanism and Gaussian encoding module for multi-label activity recognition. By leveraging the reduced attention heads and simplified encoder layers of LTHAT, we enhance the model\u2019s performance in multi-user settings while maintaining accuracy and efficiency. Extensive experiments on the WiMANS dataset show that the LTHAT network outperforms conventional models, offering superior accuracy and real-time performance suitable for deployment on edge devices and IoT sensors. This work presents a scalable, practical solution for real-time HAR applications in smart environments.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/RICAI64321.2024.10911416?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/RICAI64321.2024.10911416, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2350337361", "name": "Jianfei Lu"}, {"authorId": "2283956292", "name": "Fucheng Miao"}, {"authorId": "2238052429", "name": "Hong Wan"}, {"authorId": "2284073527", "name": "Zhiyi Lu"}, {"authorId": "2209324723", "name": "Youxiang Huang"}, {"authorId": "2340233340", "name": "Guan Gui"}]}
{"paperId": "58931c568d2938e709cf23d6e3bda7dea840f977", "url": "https://www.semanticscholar.org/paper/58931c568d2938e709cf23d6e3bda7dea840f977", "title": "A Self-Supervised Human Activity Recognition Approach via Body Sensor Networks in Smart City", "abstract": "In smart cities, pervasive sensing and wearable computing techniques are increasingly being employed to monitor and recognize human activities through body sensor networks, which have been widely used in urban safety, healthcare, and manufacturing. However, most researchers regard human activity recognition (HAR) as a high-cost research task requiring a large amount of labeled data, which is often unrealistic in real-world applications. To address this problem, we propose a self-supervised learning framework for HAR (SS-HAR). SS-HAR initially takes the unlabeled data generated by data augmentation as the input of the network, mines the supervised information of the unlabeled data under the effect of self-supervised learning, and uses the obtained backbone network as a feature extractor to extract activity features for subsequent classification. After that, we use part of the labeled data as the training set and extract the activity features using the backbone network for training and fitting the classifier. Then we utilize the rest of the data to verify the feasibility and effectiveness of the proposed self-supervised learning method. We have conducted multiple experiments on three publicly available datasets and one self-collected basketball activity dataset SZU_HAD_Basketball. The experimental results show that the SS-HAR method is able to achieve higher classification accuracy and stability than supervised and semi-supervised methods. Specifically, on the UCI dataset, SS-HAR achieves better classification performance compared to other approaches which improve the classification accuracy by 1% over the supervised method and by 5%\u20136% over the semi-supervised method, respectively.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JSEN.2023.3282601?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JSEN.2023.3282601, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2110631735", "name": "Yu Zhou"}, {"authorId": "2222278965", "name": "Chuanshi Xie"}, {"authorId": "1933266032", "name": "Shilong Sun"}, {"authorId": "2115476619", "name": "Xiao Zhang"}, {"authorId": "46394979", "name": "Yufan Wang"}]}
{"paperId": "d1056e232feda9e3c0953bea0da654cfb7a8f5de", "url": "https://www.semanticscholar.org/paper/d1056e232feda9e3c0953bea0da654cfb7a8f5de", "title": "Human activity recognition and fall detection using convolutional neural network and transformer-based architecture", "abstract": null, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.bspc.2024.106412?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.bspc.2024.106412, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2179576117", "name": "M. A. Al-qaness"}, {"authorId": "7286047", "name": "Abdelghani Dahou"}, {"authorId": "2196344868", "name": "Mohamed E. Abd Elaziz"}, {"authorId": "2285178753", "name": "Ahmed M. Helmi"}]}
{"paperId": "ac5fff2daec30a29bd36bd7577da6c0e6570b9ac", "url": "https://www.semanticscholar.org/paper/ac5fff2daec30a29bd36bd7577da6c0e6570b9ac", "title": "HARMamba: Efficient and Lightweight Wearable Sensor Human Activity Recognition Based on Bidirectional Mamba", "abstract": "Wearable sensor-based human activity recognition (HAR) is a critical research domain in activity perception. However, achieving high efficiency and long sequence recognition remains a challenge. Despite the extensive investigation of temporal deep learning models, such as convolutional neural networks, RNNs, and transformers, their extensive parameters often pose significant computational and memory constraints, rendering them less suitable for resource-constrained mobile health applications. This study introduces HARMamba, an innovative lightweight and versatile HAR architecture that combines selective bidirectional state-space model and hardware-aware design. To optimize real-time resource consumption in practical scenarios, HARMamba employs linear recursive mechanisms and parameter discretization, allowing it to selectively focus on relevant input sequences while efficiently fusing scan and recompute operations. The model employs independent channels to process sensor data streams, dividing each channel into patches and appending classification tokens to the end of the sequence. It utilizes position embedding to represent the sequence order. The patch sequence is subsequently processed by HARMamba Block, and the classification head finally outputs the activity category. The HARMamba Block serves as the fundamental component of the HARMamba architecture, enabling the effective capture of more discriminative activity sequence features. HARMamba outperforms contemporary state-of-the-art frameworks, delivering comparable or better accuracy with significantly reducing computational and memory demands. Its effectiveness has been extensively validated on four publicly available data sets, namely, PAMAP2, WISDM, UNIMIB SHAR, and UCI. The F1 scores of HARMamba on the four data sets are 99.74%, 99.20%, 88.23%, and 97.01%, respectively.", "openAccessPdf": {"url": "https://arxiv.org/pdf/2403.20183", "status": "GREEN", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2403.20183, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2291098254", "name": "Shuangjian Li"}, {"authorId": "2072832726", "name": "Tao Zhu"}, {"authorId": "2197854399", "name": "Furong Duan"}, {"authorId": "2109222039", "name": "L. Chen"}, {"authorId": "2271823433", "name": "Huansheng Ning"}, {"authorId": "2298074709", "name": "Chris D. Nugent"}, {"authorId": "2291209337", "name": "Yaping Wan"}]}
{"paperId": "8b08007d3d3610dd1783985654d97d0266090313", "url": "https://www.semanticscholar.org/paper/8b08007d3d3610dd1783985654d97d0266090313", "title": "TCN-Inception: Temporal Convolutional Network and Inception modules for sensor-based Human Activity Recognition", "abstract": null, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.future.2024.06.016?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.future.2024.06.016, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2179576117", "name": "M. A. Al-qaness"}, {"authorId": "7286047", "name": "Abdelghani Dahou"}, {"authorId": "2305943012", "name": "N. T. Trouba"}, {"authorId": "2196344868", "name": "Mohamed E. Abd Elaziz"}, {"authorId": "2285178753", "name": "Ahmed M. Helmi"}]}
{"paperId": "c645145d3d26b15f3e4e080e3510b1b53eea60e0", "url": "https://www.semanticscholar.org/paper/c645145d3d26b15f3e4e080e3510b1b53eea60e0", "title": "Human Activity Recognition Based on Deep Learning Regardless of Sensor Orientation", "abstract": "In recent years, the continuous progress of wireless communication and sensor technology has enabled sensors to be better integrated into mobile devices. Therefore, sensor-based Human Activity Recognition (HAR) has attracted widespread attention among researchers, especially in the fields of wearable technology and ubiquitous computing. In these applications, mobile devices\u2019 built-in accelerometers and gyroscopes have been typically used for human activity recognition. However, devices such as smartphones were placed in users\u2019 pockets and not fixed to their bodies, and the resulting changes in the orientation of the sensors due to users\u2019 habits or external forces can lead to a decrease in the accuracy of activity recognition. Unfortunately, there is currently a lack of publicly available datasets specifically designed to address the issue of device angle change. The contributions of this study are as follows. First, we constructed a dataset with eight different sensor placement angles using accelerometers and gyroscopes as a prerequisite for the subsequent research. Second, we introduced the Madgwick algorithm to extract quaternion mode features and alleviate the impact of angle changes on recognition performance by fusing raw accelerometer data and quaternion mode features. The resulting study provides a comprehensive analysis. On the one hand, we fine-tuned ResNet and tested its stability on our dataset, achieving a recognition accuracy of 97.13%. We included two independent experiments, one for user-related scenarios and the other for user-independent scenarios. In addition, we validated our research results on two publicly available datasets, demonstrating that our method has good generalization performance.", "openAccessPdf": {"url": "https://www.mdpi.com/2076-3417/14/9/3637/pdf?version=1714036131", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app14093637?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app14093637, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2219746160", "name": "Zhenyu He"}, {"authorId": "2298494754", "name": "Yulin Sun"}, {"authorId": "2278975742", "name": "Zhen Zhang"}]}
{"paperId": "d83aa9486a2be540035da8424d63e394603dc8b3", "url": "https://www.semanticscholar.org/paper/d83aa9486a2be540035da8424d63e394603dc8b3", "title": "Human Activity Recognition in a Free-Living Environment Using an Ear-Worn Motion Sensor", "abstract": "Human activity recognition (HAR) technology enables continuous behavior monitoring, which is particularly valuable in healthcare. This study investigates the viability of using an ear-worn motion sensor for classifying daily activities, including lying, sitting/standing, walking, ascending stairs, descending stairs, and running. Fifty healthy participants (between 20 and 47 years old) engaged in these activities while under monitoring. Various machine learning algorithms, ranging from interpretable shallow models to state-of-the-art deep learning approaches designed for HAR (i.e., DeepConvLSTM and ConvTransformer), were employed for classification. The results demonstrate the ear sensor\u2019s efficacy, with deep learning models achieving a 98% accuracy rate of classification. The obtained classification models are agnostic regarding which ear the sensor is worn and robust against moderate variations in sensor orientation (e.g., due to differences in auricle anatomy), meaning no initial calibration of the sensor orientation is required. The study underscores the ear\u2019s efficacy as a suitable site for monitoring human daily activity and suggests its potential for combining HAR with in-ear vital sign monitoring. This approach offers a practical method for comprehensive health monitoring by integrating sensors in a single anatomical location. This integration facilitates individualized health assessments, with potential applications in tele-monitoring, personalized health insights, and optimizing athletic training regimes.", "openAccessPdf": {"url": "https://www.mdpi.com/1424-8220/24/9/2665/pdf?version=1713858893", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11085719, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2288293739", "name": "L. Boborzi"}, {"authorId": "2298162817", "name": "Julian Decker"}, {"authorId": "2298165034", "name": "Razieh Rezaei"}, {"authorId": "2251958245", "name": "R. Schniepp"}, {"authorId": "2262050350", "name": "M. Wuehr"}]}
{"paperId": "131b510dbe8c8b666ba862188ab7439bb3b4159b", "url": "https://www.semanticscholar.org/paper/131b510dbe8c8b666ba862188ab7439bb3b4159b", "title": "Real-Time Sensor-Based Human Activity Recognition for eFitness and eHealth Platforms", "abstract": "Human Activity Recognition (HAR) plays an important role in the automation of various tasks related to activity tracking in such areas as healthcare and eldercare (telerehabilitation, telemonitoring), security, ergonomics, entertainment (fitness, sports promotion, human\u2013computer interaction, video games), and intelligent environments. This paper tackles the problem of real-time recognition and repetition counting of 12 types of exercises performed during athletic workouts. Our approach is based on the deep neural network model fed by the signal from a 9-axis motion sensor (IMU) placed on the chest. The model can be run on mobile platforms (iOS, Android). We discuss design requirements for the system and their impact on data collection protocols. We present architecture based on an encoder pretrained with contrastive learning. Compared to end-to-end training, the presented approach significantly improves the developed model\u2019s quality in terms of accuracy (F1 score, MAPE) and robustness (false-positive rate) during background activity. We make the AIDLAB-HAR dataset publicly available to encourage further research.", "openAccessPdf": {"url": "https://www.mdpi.com/1424-8220/24/12/3891/pdf?version=1718455444", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11207732, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2261741740", "name": "Lukasz Czekaj"}, {"authorId": "2307170315", "name": "Mateusz Kowalewski"}, {"authorId": "2148559830", "name": "Jakub Domaszewicz"}, {"authorId": "11389114", "name": "Robert Kit\u0142owski"}, {"authorId": "2261739888", "name": "Mariusz Szwoch"}, {"authorId": "2140929449", "name": "W\u0142odzia\u0142aw Duch"}]}
{"paperId": "90fa775750906062af271d2997d1ba2af73abf47", "url": "https://www.semanticscholar.org/paper/90fa775750906062af271d2997d1ba2af73abf47", "title": "Limitations in Employing Natural Language Supervision for Sensor-Based Human Activity Recognition - And Ways to Overcome Them", "abstract": "Cross-modal contrastive pre-training between natural language and other modalities, e.g., vision and audio, has demonstrated astonishing performance and effectiveness across a diverse variety of tasks and domains. In this paper, we investigate whether such natural language supervision can be used for wearable sensor based Human Activity Recognition (HAR), and discover that-surprisingly-it performs substantially worse than standard end-to-end training and self-supervision. We identify the primary causes for this as: sensor heterogeneity and the lack of rich, diverse text descriptions of activities. To mitigate their impact, we also develop strategies and assess their effectiveness through an extensive experimental evaluation. These strategies lead to significant increases in activity recognition, bringing performance closer to supervised and self-supervised training, while also enabling the recognition of unseen activities and cross modal retrieval of videos. Overall, our work paves the way for better sensor-language learning, ultimately leading to the development of foundational models for HAR using wearables.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.12023, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "1396120509", "name": "H. Haresamudram"}, {"authorId": "1932198782", "name": "Apoorva Beedu"}, {"authorId": "144558515", "name": "Mashfiqui Rabbi"}, {"authorId": "2316804367", "name": "Sankalita Saha"}, {"authorId": "145955800", "name": "Irfan Essa"}, {"authorId": "2302404251", "name": "Thomas Ploetz"}]}
{"paperId": "19daab86caca776a44c6b1e4d71857b9555ab57c", "url": "https://www.semanticscholar.org/paper/19daab86caca776a44c6b1e4d71857b9555ab57c", "title": "Revisiting Large-Kernel CNN Design via Structural Re-Parameterization for Sensor-Based Human Activity Recognition", "abstract": "During recent years, human activity recognition (HAR) using smart wearable sensors has become a main research focus in ubiquitous computing scenario. Deep convolutional neural networks (CNNs) have achieved significant success in HAR due to their automatic feature extracting ability in capturing local activity details. Due to superior performance, previous most works always prefer to apply small kernels instead of large kernels to handle time series sensor data for activity recognition. However, they do not intend to answer the key questions: why do large kernels underperform small kernels? How to close the performance gap? Intuitively, benefiting from larger receptive field (RF), larger kernels should have a great potential to model long-range dependencies in time series sensor data. So far, there has been little effort devoted to the larger-kernel design. In this article, we revisit the design of larger-kernel convolutions, which long have been neglected in the context of HAR. We find that both identity shortcut and structural re-parameterization can fully unleash the potential of larger-kernel convolutions. Extensive experiments and ablation studies on four mainstream benchmark datasets including PAMAP2, USC-HAD, UniMiB-SHAR, and OPPORTUNITY, show that our larger-kernel convolutions can further push the limit of small-kernel CNN performances under similar inference time, which can be used a drop-in replacement for small-kernel conv layers. For example, compared to the small-kernel baselines, our proposed approach can consistently boost recognition accuracy by 0.55%, 1.00%, 3.94%, and 1.64% on PAMAP2, USC-HAD, UniMiB-SHAR, and OPPORTUNITY, respectively, which is very competitive among the state-of-the-arts (SOTA). We believe that the incurred high performance is mainly due to larger effective RFs built via large kernels. The practical inference time is evaluated on a real hardware device. Our code can be available at: https://github.com/MinghuiYao/ELK-HAR/.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JSEN.2024.3371462?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JSEN.2024.3371462, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2291179416", "name": "Minghui Yao"}, {"authorId": "2152830323", "name": "Lei Zhang"}, {"authorId": "2216897261", "name": "Dongzhou Cheng"}, {"authorId": "2290076165", "name": "Lutong Qin"}, {"authorId": "2291409639", "name": "Xin Liu"}, {"authorId": "2291271995", "name": "Zenan Fu"}, {"authorId": "2254288040", "name": "Hao Wu"}, {"authorId": "2119319577", "name": "Aiguo Song"}]}
{"paperId": "d52590c224ce1b087bd77c217672288529812b77", "url": "https://www.semanticscholar.org/paper/d52590c224ce1b087bd77c217672288529812b77", "title": "The effectiveness of simple heuristic features in sensor orientation and placement problems in human activity recognition using a single smartphone accelerometer", "abstract": "Background Human activity Recognition (HAR) using smartphone sensors suffers from two major problems: sensor orientation and placement. Sensor orientation and sensor placement problems refer to the variation in sensor signal for a particular activity due to sensors\u2019 altering orientation and placement. Extracting orientation and position invariant features from raw sensor signals is a simple solution for tackling these problems. Using few heuristic features rather than numerous time-domain and frequency-domain features offers more simplicity in this approach. The heuristic features are features which have very minimal effects of sensor orientation and placement. In this study, we evaluated the effectiveness of four simple heuristic features in solving the sensor orientation and placement problems using a 1D-CNN\u2013LSTM model for a data set consisting of over 12 million samples. Methods We accumulated data from 42 participants for six common daily activities: Lying, Sitting, Walking, and Running at 3-Metabolic Equivalent of Tasks (METs), 5-METs and 7-METs from a single accelerometer sensor of a smartphone. We conducted our study for three smartphone positions: Pocket, Backpack and Hand. We extracted simple heuristic features from the accelerometer data and used them to train and test a 1D-CNN\u2013LSTM model to evaluate their effectiveness in solving sensor orientation and placement problems. Results We performed intra-position and inter-position evaluations. In intra-position evaluation, we trained and tested the model using data from the same smartphone position, whereas, in inter-position evaluation, the training and test data was from different smartphone positions. For intra-position evaluation, we acquired 70\u201373% accuracy; for inter-position cases, the accuracies ranged between 59 and 69%. Moreover, we performed participant-specific and activity-specific analyses. Conclusions We found that the simple heuristic features are considerably effective in solving orientation problems. With further development, such as fusing the heuristic features with other methods that eliminate placement issues, we can also achieve a better result than the outcome we achieved using the heuristic features for the sensor placement problem. In addition, we found the heuristic features to be more effective in recognizing high-intensity activities.", "openAccessPdf": {"url": "https://biomedical-engineering-online.biomedcentral.com/counter/pdf/10.1186/s12938-024-01213-3", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10874570, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "1699597688", "name": "Arnab Barua"}, {"authorId": "2284527133", "name": "Xianta Jiang"}, {"authorId": "144004839", "name": "Daniel Fuller"}]}
{"paperId": "5d797ddadcc5386b2bd8072af6b58fe06f007186", "url": "https://www.semanticscholar.org/paper/5d797ddadcc5386b2bd8072af6b58fe06f007186", "title": "Machine Learning Techniques for Sensor-Based Human Activity Recognition with Data Heterogeneity\u2014A Review", "abstract": "Sensor-based Human Activity Recognition (HAR) is crucial in ubiquitous computing, analyzing behaviors through multi-dimensional observations. Despite research progress, HAR confronts challenges, particularly in data distribution assumptions. Most studies assume uniform data distributions across datasets, contrasting with the varied nature of practical sensor data in human activities. Addressing data heterogeneity issues can improve performance, reduce computational costs, and aid in developing personalized, adaptive models with fewer annotated data. This review investigates how machine learning addresses data heterogeneity in HAR by categorizing data heterogeneity types, applying corresponding suitable machine learning methods, summarizing available datasets, and discussing future challenges.", "openAccessPdf": {"url": "", "status": null, "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2403.15422, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Review", "JournalArticle"], "authors": [{"authorId": "2293315269", "name": "Xiaozhou Ye"}, {"authorId": "2258707908", "name": "Kouichi Sakurai"}, {"authorId": "2293313597", "name": "Nirmal Nair"}, {"authorId": "2293278208", "name": "Kevin I-Kai Wang"}]}
{"paperId": "d5b658a17eb492e10b63c69043a515005d637e39", "url": "https://www.semanticscholar.org/paper/d5b658a17eb492e10b63c69043a515005d637e39", "title": "Modeling transformer architecture with attention layer for human activity recognition", "abstract": null, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This paper's abstract has been elided by the publisher. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s00521-023-09362-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s00521-023-09362-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "134025559", "name": "Gunjan Pareek"}, {"authorId": "39727023", "name": "S. Nigam"}, {"authorId": "2115744225", "name": "Rajiv Singh"}]}
{"paperId": "585c477080cfcd099f26b48efb061f33c85d3ffc", "url": "https://www.semanticscholar.org/paper/585c477080cfcd099f26b48efb061f33c85d3ffc", "title": "Cross-Attention Enhanced Pyramid Multi-Scale Networks for Sensor-Based Human Activity Recognition", "abstract": "Human Activity Recognition (HAR) has recently attracted widespread attention, with the effective application of this technology helping people in areas such as healthcare, smart homes, and gait analysis. Deep learning methods have shown remarkable performance in HAR. A pivotal challenge is the trade-off between recognition accuracy and computational efficiency, especially in resource-constrained mobile devices. This challenge necessitates the development of models that enhance feature representation capabilities without imposing additional computational burdens. Addressing this, we introduce a novel HAR model leveraging deep learning, ingeniously designed to navigate the accuracy-efficiency trade-off. The model comprises two innovative modules: 1) Pyramid Multi-scale Convolutional Network (PMCN), which is designed with a symmetric structure and is capable of obtaining a rich receptive field at a finer level through its multiscale representation capability; 2) Cross-Attention Mechanism, which establishes interrelationships among sensor dimensions, temporal dimensions, and channel dimensions, and effectively enhances useful information while suppressing irrelevant data. The proposed model is rigorously evaluated across four diverse datasets: UCI, WISDM, PAMAP2, and OPPORTUNITY. Additional ablation and comparative studies are conducted to comprehensively assess the performance of the model. Experimental results demonstrate that the proposed model achieves superior activity recognition accuracy while maintaining low computational overhead.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JBHI.2024.3377353?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JBHI.2024.3377353, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2215404016", "name": "Hongsen Pang"}, {"authorId": "2291460725", "name": "Li Zheng"}, {"authorId": "2280922522", "name": "Hongbin Fang"}]}
{"paperId": "c70f5988d9198bb1ab53fd918a42a827677d15a5", "url": "https://www.semanticscholar.org/paper/c70f5988d9198bb1ab53fd918a42a827677d15a5", "title": "Self-supervised learning with randomized cross-sensor masked reconstruction for human activity recognition", "abstract": null, "openAccessPdf": {"url": "https://doi.org/10.1016/j.engappai.2023.107478", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.engappai.2023.107478?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.engappai.2023.107478, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "1424412732", "name": "Aleksej Logacjov"}, {"authorId": "2266930561", "name": "Kerstin Bach"}]}
{"paperId": "4a871fb86bf111e2ddf7315692bd34f74227f20e", "url": "https://www.semanticscholar.org/paper/4a871fb86bf111e2ddf7315692bd34f74227f20e", "title": "Wearable Sensor-Based Residual Multifeature Fusion Shrinkage Networks for Human Activity Recognition", "abstract": "Human activity recognition (HAR) based on wearable sensors has emerged as a low-cost key-enabling technology for applications such as human\u2013computer interaction and healthcare. In wearable sensor-based HAR, deep learning is desired for extracting human active features. Due to the spatiotemporal dynamic of human activity, a special deep learning network for recognizing the temporal continuous activities of humans is required to improve the recognition accuracy for supporting advanced HAR applications. To this end, a residual multifeature fusion shrinkage network (RMFSN) is proposed. The RMFSN is an improved residual network which consists of a multi-branch framework, a channel attention shrinkage block (CASB), and a classifier network. The special multi-branch framework utilizes a 1D-CNN, a lightweight temporal attention mechanism, and a multi-scale feature extraction method to capture diverse activity features via multiple branches. The CASB is proposed to automatically select key features from the diverse features for each activity, and the classifier network outputs the final recognition results. Experimental results have shown that the accuracy of the proposed RMFSN for the public datasets UCI-HAR, WISDM, and OPPORTUNITY are 98.13%, 98.35%, and 93.89%, respectively. In comparison with existing advanced methods, the proposed RMFSN could achieve higher accuracy while requiring fewer model parameters.", "openAccessPdf": {"url": "https://www.mdpi.com/1424-8220/24/3/758/pdf?version=1706090106", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10857031, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2281095955", "name": "Fancheng Zeng"}, {"authorId": "2281256164", "name": "Mian Guo"}, {"authorId": "2281428157", "name": "Long Tan"}, {"authorId": "2281282506", "name": "Fa Guo"}, {"authorId": "2109305929", "name": "Xiushan Liu"}]}
{"paperId": "f655f6cba69b49a818af6478aa64149f9955823f", "url": "https://www.semanticscholar.org/paper/f655f6cba69b49a818af6478aa64149f9955823f", "title": "Using Graphs to Perform Effective Sensor-Based Human Activity Recognition in Smart Homes", "abstract": "There has been a resurgence of applications focused on human activity recognition (HAR) in smart homes, especially in the field of ambient intelligence and assisted-living technologies. However, such applications present numerous significant challenges to any automated analysis system operating in the real world, such as variability, sparsity, and noise in sensor measurements. Although state-of-the-art HAR systems have made considerable strides in addressing some of these challenges, they suffer from a practical limitation: they require successful pre-segmentation of continuous sensor data streams prior to automated recognition, i.e., they assume that an oracle is present during deployment, and that it is capable of identifying time windows of interest across discrete sensor events. To overcome this limitation, we propose a novel graph-guided neural network approach that performs activity recognition by learning explicit co-firing relationships between sensors. We accomplish this by learning a more expressive graph structure representing the sensor network in a smart home in a data-driven manner. Our approach maps discrete input sensor measurements to a feature space through the application of attention mechanisms and hierarchical pooling of node embeddings. We demonstrate the effectiveness of our proposed approach by conducting several experiments on CASAS datasets, showing that the resulting graph-guided neural network outperforms the state-of-the-art method for HAR in smart homes across multiple datasets and by large margins. These results are promising because they push HAR for smart homes closer to real-world applications.", "openAccessPdf": {"url": "https://www.mdpi.com/1424-8220/24/12/3944/pdf?version=1718767414", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11207551, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2307479536", "name": "Srivatsa P"}, {"authorId": "2238505767", "name": "Thomas Ploetz"}]}
{"paperId": "83195960ae82dcf806eee8b4e4577e19715de413", "url": "https://www.semanticscholar.org/paper/83195960ae82dcf806eee8b4e4577e19715de413", "title": "A Survey of LoRaWAN-Integrated Wearable Sensor Networks for Human Activity Recognition: Applications, Challenges and Possible Solutions", "abstract": "Long-Range Wide Area Networks (LoRaWAN), a prominent technology within Low-Power Wide Area Networks (LPWANs), have gained traction in remote monitoring due to their long-range communication, scalability, and low energy consumption. Compared to other LPWANs like Sigfox, Ingenu Random Phase Multiple Access (Ingenu-RPMA), Long-Term Evolution for Machines (LTE-M), and Narrowband Internet of Things (NB-IoT), LoRaWAN offers superior adaptability in diverse environments. This adaptability makes it particularly effective for Human Activity Recognition (HAR) systems. These systems utilize wearable sensors to collect data for applications in healthcare, elderly care, sports, and environmental monitoring. Integrating LoRaWAN with edge computing and Internet of Things (IoT) frameworks enhances data processing and transmission efficiency. However, challenges such as sensor wearability, data payload constraints, energy efficiency, and security must be addressed to deploy LoRaWAN-based HAR systems in real-world applications effectively. This survey explores the integration of LoRaWAN technology with wearable sensors for HAR, highlighting its suitability for remote monitoring applications such as Activities of Daily Living (ADL), tracking and localization, healthcare, and safety. We categorize state-of-the-art LoRaWAN-integrated wearable systems into body-worn, hybrid, objectmounted, and ambient sensors. We then discuss their applications and challenges, including energy efficiency, sensor scalability, data constraints, and security. Potential solutions such as advanced edge processing algorithms and secure communication protocols are proposed to enhance system performance and user comfort. The survey also outlines specific future research directions to advance this evolving field.", "openAccessPdf": {"url": "https://doi.org/10.1109/ojcoms.2024.3484002", "status": "GOLD", "license": "CCBYNCND", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/OJCOMS.2024.3484002?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/OJCOMS.2024.3484002, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Review"], "authors": [{"authorId": "2215745644", "name": "Nahshon Mokua Obiri"}, {"authorId": "2077362506", "name": "K. Van Laerhoven"}]}
{"paperId": "d6f4ee6f9c620cf3964bd8e0cb80920f59f69e4c", "url": "https://www.semanticscholar.org/paper/d6f4ee6f9c620cf3964bd8e0cb80920f59f69e4c", "title": "Layout Agnostic Human Activity Recognition in Smart Homes through Textual Descriptions Of Sensor Triggers (TDOST)", "abstract": "Human activity recognition (HAR) using ambient sensors in smart homes has numerous applications for human healthcare and wellness. However, building general-purpose HAR models that can be deployed to new smart home environments requires a significant amount of annotated sensor data and training overhead. Most smart homes vary significantly in their layouts, i.e., floor plans and the specifics of sensors embedded, resulting in low generalizability of HAR models trained for specific homes. We address this limitation by introducing a novel, layout-agnostic modeling approach for HAR systems in smart homes that utilizes the transferrable representational capacity of natural language descriptions of raw sensor data. To this end, we generate Textual Descriptions Of Sensor Triggers (TDOST) that encapsulate the surrounding trigger conditions and provide cues for underlying activities to the activity recognition models. Leveraging textual embeddings, rather than raw sensor data, we create activity recognition systems that predict standard activities across homes without (re-)training or adaptation to target homes. Through an extensive evaluation, we demonstrate the effectiveness of TDOST-based models in unseen smart homes through experiments on benchmark Orange4Home and CASAS datasets. Furthermore, we conduct a detailed analysis of how the individual components of our approach affect downstream activity recognition performance.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2405.12368, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2253456849", "name": "Megha Thukral"}, {"authorId": "80667186", "name": "Sourish Gunesh Dhekane"}, {"authorId": "10813555", "name": "S. Hiremath"}, {"authorId": "1396120509", "name": "H. Haresamudram"}, {"authorId": "2302404251", "name": "Thomas Ploetz"}]}
{"paperId": "b06b2ce0b885547af292e5c508d4d20ab7dd7e3c", "url": "https://www.semanticscholar.org/paper/b06b2ce0b885547af292e5c508d4d20ab7dd7e3c", "title": "Towards LLM-Powered Ambient Sensor Based Multi-Person Human Activity Recognition", "abstract": "Human Activity Recognition (HAR) is one of the central problems in fields such as healthcare, elderly care, and security at home. However, traditional ambient-sensor-based HAR approaches face challenges including data scarcity, difficulties in model generalization, and the complexity of recognizing activities in multi-person scenarios. This paper proposes a large-language-model-based framework called LAHAR which addresses HAR in multi-person scenarios. By endowing LLMs with inter-sensor relevance estimation and sensor-subject relevance estimation abilities, LAHAR can assign sensor events to the corresponding subjects. By providing action-level descriptions of sensor events and subsequently performing activity-level reasoning based on these descriptions, LAHAR is ultimately able to process data spanning several tens of hours with second-level resolution and results in an activity timeline for each subject. We validated LAHAR on the ARAS dataset. The results demonstrate that LAHAR achieves comparable accuracy to the state-of-the-art method at higher resolutions and maintains robustness in multiperson scenarios.", "openAccessPdf": {"url": "http://arxiv.org/pdf/2407.09529", "status": "GREEN", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2407.09529, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2296439801", "name": "Xi Chen"}, {"authorId": "2712374", "name": "Julien Cumin"}, {"authorId": "2502343", "name": "F. Ramparany"}, {"authorId": "2256181215", "name": "Dominique Vaufreydaz"}]}
{"paperId": "da377e5152ca1198bcbc1d5092a8c5be0ffb9e26", "url": "https://www.semanticscholar.org/paper/da377e5152ca1198bcbc1d5092a8c5be0ffb9e26", "title": "Beyond Isolated Frames: Enhancing Sensor-Based Human Activity Recognition through Intra- and Inter-Frame Attention", "abstract": "Human Activity Recognition (HAR) has become increasingly popular with ubiquitous computing, driven by the popularity of wearable sensors in fields like healthcare and sports. While Convolutional Neural Networks (ConvNets) have significantly contributed to HAR, they often adopt a frame-by-frame analysis, concentrating on individual frames and potentially overlooking the broader temporal dynamics inherent in human activities. To address this, we propose the intra- and inter-frame attention model. This model captures both the nuances within individual frames and the broader contextual relationships across multiple frames, offering a comprehensive perspective on sequential data. We further enrich the temporal understanding by proposing a novel time-sequential batch learning strategy. This learning strategy preserves the chronological sequence of time-series data within each batch, ensuring the continuity and integrity of temporal patterns in sensor-based HAR.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2405.19349, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2303844157", "name": "Shuai Shao"}, {"authorId": "2304675166", "name": "Yu Guan"}, {"authorId": "2303844069", "name": "Victor Sanchez"}]}
{"paperId": "39dfbcce14cd7c7117271b96327ee10d04180079", "url": "https://www.semanticscholar.org/paper/39dfbcce14cd7c7117271b96327ee10d04180079", "title": "Domain Adaptation for Sensor-Based Human Activity Recognition with a Graph Convolutional Network", "abstract": "Sensor-based human activity recognition (HAR) plays a fundamental role in various mobile application scenarios, but the model performance of HAR heavily relies on the richness of the dataset and the completeness of data annotation. To address the shortage of comprehensive activity types in collected datasets, we adopt the domain adaptation technique with a graph neural network-based approach by incorporating an adaptive learning mechanism to enhance the action recognition model\u2019s generalization ability, especially when faced with limited sample sizes. To evaluate the effectiveness of our proposed approach, we conducted experiments using three well-known datasets: MHealth, PAMAP2, and TNDA. The experimental results demonstrate the efficacy of our approach in sensor-based HAR tasks, achieving impressive average accuracies of 98.88%, 98.58%, and 97.78% based on the respective datasets. Furthermore, we conducted transfer learning experiments to address the domain adaptation problem. These experiments revealed that our proposed model exhibits exceptional transferability and distinguishing ability, even in scenarios with limited available samples. Thus, our approach offers a practical and viable solution for sensor-based HAR tasks.", "openAccessPdf": {"url": "https://www.mdpi.com/2227-7390/12/4/556/pdf?version=1707734055", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/math12040556?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/math12040556, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2284049885", "name": "Jing Yang"}, {"authorId": "2283991024", "name": "Tianzheng Liao"}, {"authorId": "2284115586", "name": "Jingjing Zhao"}, {"authorId": "2280051615", "name": "Yan Yan"}, {"authorId": "2284026661", "name": "Yichun Huang"}, {"authorId": "2244941668", "name": "Zhijia Zhao"}, {"authorId": "2284181447", "name": "Jing Xiong"}, {"authorId": "2284128337", "name": "Changhong Liu"}]}
{"paperId": "7b8eea06f96ef5e9b2e7f9a0027307a3bcbdd058", "url": "https://www.semanticscholar.org/paper/7b8eea06f96ef5e9b2e7f9a0027307a3bcbdd058", "title": "DWOSC: Dynamic Weight Optimization and Smoothness Constraint for Sensor-Based Human Activity Recognition", "abstract": "The sensor-based human activity recognition (SHAR) task aims to detect and analyze signals captured by various sensors embedded in intelligent devices to assist people\u2019s daily lives, which inherently have variations, spatial inconsistency, and noise characteristics. Inspired by the success of deep learning, many researchers have designed various neural network architectures to improve the SHAR model\u2019s performance. Albeit effective, these manners are not optimal due to ignoring the imbalance and difficulty of interclass and intraclass of sensor inherently characteristic, which proposes the challenge for resource-constrained devices. To address this challenge, we present a simple and effective optimization strategy for sensor signal processing, including dynamic weight optimization (DWO) and smoothness constraint (SC) strategies, termed DWOSC, which provide a framework to optimize loss function and enhance activity recognition performance. The DWO aims to address the class imbalance and hard-to-recognize samples. The SC seeks to maintain the smoothness of decision boundaries for complex samples. This way, the proposed approach can achieve a more stable convergence of the model and further improve the SHAR task\u2019s performance without raising complexity. Extensive experiments conducted on three benchmark SHAR datasets, e.g., OPPORTUNITY, University of Southern California Human Activity Dataset (USC-HAD), and UniMib, demonstrate the superiority of our method over the deep learning baselines and existing SHAR works.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TIM.2024.3366277?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TIM.2024.3366277, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2275865792", "name": "Ying Li"}, {"authorId": "2146668677", "name": "Junsheng Wu"}, {"authorId": "2129485571", "name": "Weigang Li"}, {"authorId": "2275669670", "name": "Aiqing Fang"}]}
{"paperId": "e596d77fd138b3cd6b0d8f8f7bbf245732cb95c9", "url": "https://www.semanticscholar.org/paper/e596d77fd138b3cd6b0d8f8f7bbf245732cb95c9", "title": "Sensor Data Augmentation from Skeleton Pose Sequences for Improving Human Activity Recognition", "abstract": "The proliferation of deep learning has significantly advanced various fields, yet Human Activity Recognition (HAR) has not fully capitalized on these developments, primarily due to the scarcity of labeled datasets. Despite the integration of advanced Inertial Measurement Units (IMUs) in ubiquitous wearable devices like smartwatches and fitness trackers, which offer self-labeled activity data from users, the volume of labeled data remains insufficient compared to domains where deep learning has achieved remarkable success. Addressing this gap, in this paper, we propose a novel approach to improve wearable sensor-based HAR by introducing a pose-to-sensor network model that generates sensor data directly from 3D skeleton pose sequences. our method simultaneously trains the pose-to-sensor network and a human activity classifier, optimizing both data reconstruction and activity recognition. Our contributions include the integration of simultaneous training, direct pose-to-sensor generation, and a comprehensive evaluation on the MM-Fit dataset. Experimental results demonstrate the superiority of our framework with significant performance improvements over baseline methods.", "openAccessPdf": {"url": "http://arxiv.org/pdf/2406.16886", "status": "GREEN", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2406.16886, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2308099167", "name": "Parham Zolfaghari"}, {"authorId": "34791167", "name": "V. F. Rey"}, {"authorId": "2212784284", "name": "L. Ray"}, {"authorId": "2308265020", "name": "Hyun Kim"}, {"authorId": "2012740", "name": "Sungho Suh"}, {"authorId": "2199139669", "name": "P. Lukowicz"}]}
{"paperId": "72ad9f2cfb7d3aa3ffbc250be956cd5e05f405e6", "url": "https://www.semanticscholar.org/paper/72ad9f2cfb7d3aa3ffbc250be956cd5e05f405e6", "title": "Past, Present, and Future of Sensor-based Human Activity Recognition using Wearables: A Surveying Tutorial on a Still Challenging Task", "abstract": "In the many years since the inception of wearable sensor-based Human Activity Recognition (HAR), a wide variety of methods have been introduced and evaluated for their ability to recognize activities. Substantial gains have been made since the days of hand-crafting heuristics as features, yet, progress has seemingly stalled on many popular benchmarks, with performance falling short of what may be considered 'sufficient'-- despite the increase in computational power and scale of sensor data, as well as rising complexity in techniques being employed. The HAR community approaches a new paradigm shift, this time incorporating world knowledge from foundational models. In this paper, we take stock of sensor-based HAR -- surveying it from its beginnings to the current state of the field, and charting its future. This is accompanied by a hands-on tutorial, through which we guide practitioners in developing HAR systems for real-world application scenarios. We provide a compendium for novices and experts alike, of methods that aim at finally solving the activity recognition problem.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2411.14452, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Review"], "authors": [{"authorId": "1396120509", "name": "H. Haresamudram"}, {"authorId": "2256777349", "name": "Chi Ian Tang"}, {"authorId": "2012740", "name": "Sungho Suh"}, {"authorId": "2199139669", "name": "P. Lukowicz"}, {"authorId": "2268947958", "name": "Thomas Ploetz"}]}
{"paperId": "02c2ccb1d5884b5a348c75d575629a91cff1281d", "url": "https://www.semanticscholar.org/paper/02c2ccb1d5884b5a348c75d575629a91cff1281d", "title": "Improving Performance and Explainability of Sensor-Based Human Activity Recognition", "abstract": null, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This paper's abstract has been elided by the publisher. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ECTIDAMTNCON60518.2024.10480073?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ECTIDAMTNCON60518.2024.10480073, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "9130999", "name": "S. Mekruksavanich"}, {"authorId": "2131076643", "name": "Ponnipa Jantawong"}, {"authorId": "9223341", "name": "A. Jitpattanakul"}]}
{"paperId": "88fafcc16e45cb2024db19ff33f0a85d3171c762", "url": "https://www.semanticscholar.org/paper/88fafcc16e45cb2024db19ff33f0a85d3171c762", "title": "Human Activity Recognition using EfficientNet for Wearable Sensor Data", "abstract": "Human Activity Recognition (HAR) has attracted considerable attention from researchers due to its broad implications in healthcare, smart environments, and entertainment. HAR involves the usage of sensor devices and the Internet of Things (IoT). Human Activity Recognition (HAR) has emerged as a crucial application in health monitoring, necessitating the ongoing utilization of Smart phones, smart watches, and wearable devices to document and track patients\u2019 everyday activities. Deep learning (DL)-based algorithms have shown effective in predicting various human actions using time-series data collected from cell phones and wearable sensors. Deep learning-based methods have faced challenges when used to time-series data in activity recognition. The proposed methodology has the potential to effectively address those concerns. In this paper a novel approach is proposed using EfficientNet by adding various layers during the classification phase. Proposed method is evaluated by using UCI-HAR dataset and PAMAPS2 dataset, Class imbalance during training and testing phase is reduced by using various data augmentation methods. Proposed method achieved an accuracy of 99.98 on PAMAPS dataset thereby achieving significant results than state of art methods.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/IC3IoT60841.2024.10550387?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IC3IoT60841.2024.10550387, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2294764675", "name": "V. Rahul Chiranjeevi"}, {"authorId": "145059321", "name": "B. Murugan"}, {"authorId": "2267234550", "name": "S. Dhanasekaran"}, {"authorId": "2277669477", "name": "S. Senthil Pandi"}]}
{"paperId": "2d1e476a96d640e76ff9cbd005f8bbad12eeba59", "url": "https://www.semanticscholar.org/paper/2d1e476a96d640e76ff9cbd005f8bbad12eeba59", "title": "Hand-Crafted Features With a Simple Deep Learning Architecture for Sensor-Based Human Activity Recognition", "abstract": "With the growth in the wearable device market, wearable sensor-based human activity recognition (HAR) systems have been gaining increasing interest in research because of their rising demands in many areas. This article presents a novel sensor-based HAR system that utilizes a unique feature extraction technique associated with a deep learning (DL) method for classification. One of the main contributions of this work is dividing the sensor sequences timewise into nonoverlapping 2-D segments. Then, statistical features are computed from each 2-D segment using two approaches; the first approach computes features from the raw sensor readings, while the second approach applies time-series differencing to sensor readings prior to feature calculations. Applying time-series differencing to 2-D segments helps in identifying the underlying structure and dynamics of the sensor reading across time. This work experiments with different numbers of 2-D segments of sensor reading sequences. Also, it reports results with and without the use of different components of the proposed system. Additionally, it analyses the best-performing models\u2019 complexity, comparing them with other models trained by integrating the proposed method with an existing transformer network. All of these arrangements are tested with different DL architectures supported by an attention layer to enhance the model. Four benchmark datasets are used to perform several experiments, namely, Mobile Health (mHealth), ubiquitous computing human activity dataset (USC-HAD), University of California Irvine HAR (UCI-HAR) dataset, and daily and sports activities (DSA). The experimental results revealed that the proposed system outperforms HAR rates reported in the most recent studies. Specifically, this work reports recognition rates of 99.17%, 81.07%, 99.44%, and 94.03% for the four datasets, respectively.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JSEN.2024.3422272?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JSEN.2024.3422272, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2158430845", "name": "Yaman Albadawi"}, {"authorId": "1805004", "name": "T. Shanableh"}]}
{"paperId": "7059b702bf2ec49697975244ee09fb1e03932a01", "url": "https://www.semanticscholar.org/paper/7059b702bf2ec49697975244ee09fb1e03932a01", "title": "Improving Human Activity Recognition Through Multisensor Data Fusion Techniques in Wireless Sensor Networks", "abstract": "Wireless Sensor Networks (WSNs) have revolutionized data collection, especially in Human Activity Recognition (HAR). Multisensor datasets are crucial for a comprehensive understanding of human behavior, enabling more advanced classification techniques. This study explores the essential role of machine learning in categorizing activities, especially given the abundance of available multi-sensor data from WSN. The research utilizes information fusion as a pivotal mechanism to boost the accuracy of activity classifications. Employing Support Vector Machine (SVM) and Decision Tree (DT) algorithms, the project utilizes advanced data fusion techniques, specifically Kalman Filter (KF) and Covariance Intersection (CI), to optimize information extraction from the provided data. The study encompasses six experiments, including applying SVM and DT on raw data, SVM and DT on data fused by CI, and SVM and DT on data fused by KF. The results of these experiments reveal a significant improvement in the accuracy of SVM and DT classification when incorporating CI and KF. This emphasizes the effectiveness of information fusion techniques in refining the outcomes of human activity recognition systems, showcasing their vital role in enhancing the reliability and precision of activity classifications. This research not only contributes to the field of HAR but also establishes a foundation for further advancements in real-world applications where precise activity classification holds utmost importance.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICMI60790.2024.10586003?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICMI60790.2024.10586003, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2310825822", "name": "Rasha S. Gargees"}]}
{"paperId": "a3428fe7f9845117e7ae649963f182ac470da1c7", "url": "https://www.semanticscholar.org/paper/a3428fe7f9845117e7ae649963f182ac470da1c7", "title": "Sensor-Based Human Activity Recognition Based on Multi-Stream Time-Varying Features With ECA-Net Dimensionality Reduction", "abstract": "Sensor-based datasets are extensively utilized in human-computer interaction (HCI) and medical applications due to their portability and strong privacy features. Many researchers have developed sensor-based human activity recognition (HAR) systems to increase recognition performance. However, existing systems still face challenges in achieving satisfactory performance due to insufficient time-varying features and gradient explosion issues. To address these challenges, we proposed a multi-stream temporal convolutional network (TCN)-based approach for time-varying feature extraction and feature selection to recognize human activity (HA) from sensor datasets. The proposed model effectively extracts and emphasizes the spatial-temporal features of various human activities based on a 4-stream model. Each stream uses TCN to extract time-varying features and enhances them using an appropriate integration module. The first stream extracts fine-grained temporal features with TCN. The second and third streams integrate TCN features with LSTM, applying pre-integration and post-integration, respectively. The fourth stream uses CNN for spatial features and TCN for enhancing temporal features. The concatenation of the 4-stream features captures complex dependencies, improving the model\u2019s understanding of prolonged activities. In addition, we proposed a modified effective channel attention network (ECA-Net) that assigns higher dimensionality weight to lower dimensionality, enabling the proposed model to learn and recognise human activities effectively despite their complex patterns. Evaluations on the WISDM, PAMAP2, USC-HAD, Opportunity UCI, and UCI-HAR datasets showed accuracy improvements of 1.12%, 1.99%, 1.30%, 5.72%, and 0.38%, respectively, over state-of-the-art systems. The high-performance accuracy of the proposed model demonstrates its superiority, with implications for improving prosthetic limb functionality and advancing robotics human-machine interfaces. Our data preprocessing approach, deep learning model code, and dataset information are available at the following link: https://github.com/musaru/HAR_Sensor.", "openAccessPdf": {"url": "https://doi.org/10.1109/access.2024.3473828", "status": "GOLD", "license": "CCBYNCND", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2024.3473828?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2024.3473828, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "35429302", "name": "Abu Saleh Musa Miah"}, {"authorId": "2301587546", "name": "Yong Seok Hwang"}, {"authorId": "2238717213", "name": "Jungpil Shin"}]}
{"paperId": "2b2fc8fa8b1dd48ae100234beb77714da9934210", "url": "https://www.semanticscholar.org/paper/2b2fc8fa8b1dd48ae100234beb77714da9934210", "title": "Enhanced Human Activity Recognition Using Inertial Sensor Data from Smart Wearables: A Neural Network Approach with Residual Connections", "abstract": "Human Activity Recognition (HAR) has gained significant interest in various research circles due to its wide-ranging applications, including patient monitoring, gaming, and education. While computer vision has traditionally played a key role in HAR, it encounters challenges like privacy concerns and environmental factors such as occlusion. To address these issues, inertial sensors like accelerometers and gyroscopic sensors have gained popularity, offering advantages such as cost-effectiveness and increased mobility. In this study, we propose a Convolutional Neural Network (CNN) architecture for HAR that incorporates residual connections. We rigorously evaluate our model using a freely available dataset WISDM (2011) from the wireless sensor data mining lab and compare its performance with state-of-the-art techniques. Our results indicate that our proposed model not only outperforms existing methods in terms of accuracy but also exhibits reduced complexity, requiring only 38,342 trainable parameters. Our HAR model achieves an impressive average accuracy of 98.32%, along with notable F1-score, Recall, and Precision values of 97.50%. These findings underscore the efficacy of our approach in advancing HAR technology while maintaining efficiency.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICECT61618.2024.10581358?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICECT61618.2024.10581358, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2310485255", "name": "Shaida Muhammad"}, {"authorId": "2151202860", "name": "Kiran Hamza"}, {"authorId": "2139886857", "name": "H. Imran"}, {"authorId": "150310570", "name": "Saad Wazir"}]}
{"paperId": "0a769757e3df414f6c4843d704812faaf3f1ed97", "url": "https://www.semanticscholar.org/paper/0a769757e3df414f6c4843d704812faaf3f1ed97", "title": "Channel-Equalization-HAR: A Light-weight Convolutional Neural Network for Wearable Sensor Based Human Activity Recognition", "abstract": "Recently, human activity recognition (HAR) that uses wearable sensors has become a research hotspot due to its wide applications in a large variety of real-world scenarios including fitness, health-care, and sports tracking. In essence, HAR can be treated as multi-channel time series classification problem, where different channels may come from heterogeneous sensor modalities. Deep learning, especially convolutional neural networks (CNNs) have made major breakthroughs in ubiquitous HAR computing scenario. Various normalization methods have played an indispensable role in prior HAR works, which enable every layer of the network to do learning more independently by normalizing hybrid sensor features. However, normalization tends to produce a \u2018channel collapse\u2019 phenomenon, where a large fraction of channels only generates very small values. Most channels are inhibited and contribute very little to activity recognition. As a result, the network has to rely on only a few valid channels, which inevitably impair the generality ability of a network. In this paper, we provide an alternative called Channel Equalization to reactivate these inhibited channels by performing whitening or decorrelation operation, which compels all channels to contribute more or less to feature representation. Experiments conducted on several benchmarks including UCI-HAR, OPPORTUNITY, UniMiB-SHAR, WISDM, PAMAP2, and USC-HAD show that the proposed Channel Equalization module is an impressive alternative of convolution layers, and achieve higher recognition performance to baseline models with simliar computational cost, which significantly surpasses recent state-of-the-arts for activity recongition. To the best of our knowledge, the Channel Equalization is for the first time to be applied in multi-modal HAR scenario. Finally, the actual operation is evaluated on an embedded Raspberry Pi Model 3 B plus platform.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/TMC.2022.3174816?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TMC.2022.3174816, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2158104269", "name": "Wenbo Huang"}, {"authorId": "2152836514", "name": "Lei Zhang"}, {"authorId": "1664776313", "name": "Hao Wu"}, {"authorId": "2059245581", "name": "Fuhong Min"}, {"authorId": "2119319577", "name": "Aiguo Song"}]}
{"paperId": "1037c95d9079b081df26229dde8dd529c43b4e1e", "url": "https://www.semanticscholar.org/paper/1037c95d9079b081df26229dde8dd529c43b4e1e", "title": "Simple to Complex, Single to Concurrent Sensor-Based Human Activity Recognition: Perception and Open Challenges", "abstract": "Human activity recognition (HAR) has attracted considerable research attention due to its essential role in various domains, ranging from healthcare to security, safety, and entertainment. HAR has undergone a paradigm shift from simple single-task detection to the more complex task of identifying multiple simultaneous activities as technology advances. A wide range of methods, including sensing modalities, identification algorithms, a specified list of recognized activities, and end application goals, have been used in the literature to investigate activities carried out by single individuals. However, there appears to be a research gap when it comes to scenarios in which several people engage in individual or concurrent activities. Although numerous reviews and surveys have previously addressed HAR, with the continual expansion of literature, there is a necessity for an updated assessment of the status of HAR literature. The system encompasses various operational modules, including data acquisition, noise elimination, and distortion reduction through preprocessing, followed by feature extraction, feature selection, and classification. Recent advancements have introduced state-of-the-art techniques for feature extraction and selection, which are categorized using traditional machine learning classifiers. However, a notable limitation is observed, as many of these techniques rely on basic feature extraction processes, hindering their capability to recognize complex activities. This article reviews 190 articles with respect to data collection, segmentation, feature extraction, energy efficiency, personalized models, and machine learning (ML) and deep learning (DL) approaches for sensor-based HAR. Open challenges and future enhancements of HAR are also discussed in this article.", "openAccessPdf": {"url": "https://doi.org/10.1109/access.2024.3422831", "status": "GOLD", "license": "CCBYNCND", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2024.3422831?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2024.3422831, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Review"], "authors": [{"authorId": "9286397", "name": "Shilpa Ankalaki"}]}
{"paperId": "d302d4d06939fa571ed272bbfa109c78f3713a85", "url": "https://www.semanticscholar.org/paper/d302d4d06939fa571ed272bbfa109c78f3713a85", "title": "Learned Sensor Fusion For Robust Human Activity Recognition in Challenging Environments", "abstract": "Human activity recognition is a vital area of robotics with significant real-world applications, from enhancing security and surveillance to improving healthcare and human-robot interaction. A critical challenge lies in bridging the gap between research models, which often assume ideal conditions, and the complexities of real-world environments. In practice, conditions can be far from perfect, including scenarios with poor lighting, adverse weather, or blurred views. In this paper, we present an innovative approach for robust activity recognition through learned sensor fusion, in which our recognition framework identifies a latent weighted combination of input modalities, enabling classifiers to capitalize on advantages provided by various sensors. In support of our work, we have released a dataset of human activities across multiple modalities with environmental degradation factors such as darkness, fog, and thermal blur. Our proposed approach identifies a weighted combination of modality representations derived from existing architectures. We show that our approach is able to achieve 24% higher classification performance than existing single-modality approaches. Our approach also attains comparable performance to modality fusion approaches in significantly reduced classification time. In real-world robotics applications, particularly those occurring in dangerous, degraded environments, this speed is critical.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/IROS58592.2024.10802830?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IROS58592.2024.10802830, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2337119023", "name": "Max Conway"}, {"authorId": "144755330", "name": "Brian Reily"}, {"authorId": "2283059335", "name": "Christopher M. Reardon"}]}
{"paperId": "2ea868c77d01b3cd891efa3c367a71c8d230afa5", "url": "https://www.semanticscholar.org/paper/2ea868c77d01b3cd891efa3c367a71c8d230afa5", "title": "A SMARTPHONE SENSOR BASED REAL-LIFE HUMAN ACTIVITY RECOGNITION SYSTEM USING DEEP NETS METHOD", "abstract": "The proliferation of sensor devices in recent years has made Human Activity Recognition (HAR) a hotspot for academic interest. Smartphones with built-in sensors make it possible to employ such sensors for activity detection tasks like assisting the elderly with their everyday tasks. A plethora of high-tech sensors, such as global positioning systems (GPS), cameras, accelerometers, microphones, light sensors, and compass, are standard on these smartphones. Activity recognition is a promising field of study that might be used to provide consumers with flexible and efficient services. The purpose of our research is to evaluate a system that makes use of accelerometers, which are acceleration sensors that are built into smartphones. For the purpose of running the model and understanding six distinct human activities through supervised machine learning classification, twenty-six users' accelerometer data is collected while they go about their daily lives, including sitting, standing, lying down, walking, and climbing and descending stairs. Following the merging and aggregation of the sample data, supervised machine learning techniques were employed to generate prediction models from the instances. To get beyond the limitations of the lab, we used the Google Android platform and the Physics Toolbox Sensor Suite to gather this time series data. In this work, we take a look at how Machine Learning and Deep Nets have been used to address issues with human activity identification using smartphone sensors. Furthermore, we proved that data collected with lower frequencies can still serve their intended purpose. Our most basic Deep Nets model yielded a maximum accuracy of 95.71% for the male dataset and 94.62 % for the female dataset.", "openAccessPdf": {"url": "https://doi.org/10.55524/csistw.2024.12.1.4", "status": "BRONZE", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.55524/csistw.2024.12.1.4?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55524/csistw.2024.12.1.4, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": null, "authors": [{"authorId": "2297070631", "name": "Dr. Kaneez Zainab"}, {"authorId": "2297065651", "name": "Ratan Rajan Srivastava"}]}
{"paperId": "5a1cc191bfb1720a8d590914cb3cce6cfbeba7c4", "url": "https://www.semanticscholar.org/paper/5a1cc191bfb1720a8d590914cb3cce6cfbeba7c4", "title": "Sensor-Based Human Activity Recognition Using a Hybrid CNN-SVM Approach", "abstract": "Human Activity Recognition (HAR) is the process of interpreting human actions from sensor data. This paper presents a hybrid approach for HAR utilizing Convolutional Neural Network (CNN) for feature extraction and Support Vector Machine (SVM) for classification. The model is end-to-end trainable, where the SVM classifier replaces the softmax layer of the CNN. Evaluation of the approach was conducted on two benchmark datasets, UCI HAR and UniMiB SHAR, achieving accuracies of 96.13% and 87.85%, respectively. These results surpass those reported in the state-of-the-art and demonstrate the effectiveness of the proposed approach in interpreting human activities.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ISPA59904.2024.10536787?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ISPA59904.2024.10536787, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2303538323", "name": "Imene Charabi"}, {"authorId": "9259601", "name": "M. Abidine"}, {"authorId": "2616656", "name": "B. Fergani"}]}
{"paperId": "39827c7fadc4c76fe33fcf3b9bcb2c494d52a77c", "url": "https://www.semanticscholar.org/paper/39827c7fadc4c76fe33fcf3b9bcb2c494d52a77c", "title": "Exploiting Machine Learning and LSTM for Human Activity Recognition: Using Physiological and Biological Sensor Data from Actigraph", "abstract": "Human activity recognition involves identifying the daily living activities of an individual through the utilization of sensor attributes and intelligent learning algorithms. The identification of intricate human activities proves to be a labo-rious task, given the inherent difficulty of capturing long-term dependencies and extracting efficient features from unprocessed sensor data. For this purpose, this study aims at recognizing and classifying human activities using physiological and biological sensor data generated by Actigraph, as they can accurately measure moderate-to-vigorous intensity physical which is mostly affected by body composition and also better suited for self-monitoring. We examined the effectiveness of these features by applying prevalent machine learning classifiers and long short-term memory (LSTM) networks on recently publicly available data, which includes accelerometer and heart rate recordings. The results from our experiments showed that LSTM models performed better than conventional ML classifiers with the best result achieving an accuracy of 86.5%. The findings also confirms the significance of the heart rate in accurately classifying and identification of human activity more.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICIT58233.2024.10540940?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICIT58233.2024.10540940, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "2155700482", "name": "Matthew Oyeleye"}, {"authorId": "2117181236", "name": "Tianhua Chen"}, {"authorId": "2128314795", "name": "Pan Su"}, {"authorId": "1746617", "name": "G. Antoniou"}]}
{"paperId": "01710dd9256eac13af47295845d62630424dc734", "url": "https://www.semanticscholar.org/paper/01710dd9256eac13af47295845d62630424dc734", "title": "Contrastive Self-Supervised Learning for Sensor-Based Human Activity Recognition: A Review", "abstract": "Deep learning models have achieved significant success in human activity recognition, particularly in assisted living and telemonitoring. However, training these models requires substantial amounts of labeled training data, which is time-consuming and costly to acquire in real-world environments. Contrastive self-supervised learning has recently garnered attention in sensor-based activity recognition to mitigate the need for expensive large-scale data collection and annotation. Despite numerous related published papers, there remains a lack of literature reviews highlighting recent advances in contrastive self-supervised learning for sensor-based activity recognition. This paper extensively reviews 43 papers on recent contrastive self-supervised learning methods for sensor-based human activity recognition, excluding those related to video or audio sensors due to privacy concerns. First, we summarize the taxonomy of contrastive self-supervised learning, followed by a detailed description of contrastive learning models used for activity recognition and their main components. Next, we comprehensively review data augmentation methods for sensor data and commonly used benchmark datasets for activity recognition. The empirical performance comparisons of different methods are presented on benchmark datasets in linear evaluation, semi-supervised learning, and transfer learning scenarios. Through these comparisons, we derive significant insights into the selection of contrastive self-supervised models for sensor-based activity recognition. Finally, we discuss the limitations of current research and outline promising research directions for future exploration.", "openAccessPdf": {"url": "https://doi.org/10.1109/access.2024.3480814", "status": "GOLD", "license": "CCBYNCND", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2024.3480814?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2024.3480814, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Review"], "authors": [{"authorId": "2282368236", "name": "Hui Chen"}, {"authorId": "1403322736", "name": "Charles Gouin-Vallerand"}, {"authorId": "2292320526", "name": "K\u00e9vin Bouchard"}, {"authorId": "1695620", "name": "S. Gaboury"}, {"authorId": "2255044266", "name": "M. Couture"}, {"authorId": "2255051043", "name": "Nathalie Bier"}, {"authorId": "2280546338", "name": "Sylvain Giroux"}]}
{"paperId": "64f0e698f61f6eb49bf58e51cb7bddaf384ba2ab", "url": "https://www.semanticscholar.org/paper/64f0e698f61f6eb49bf58e51cb7bddaf384ba2ab", "title": "Sensor-Based Human Activity Recognition Using Image-Based 2D Discrete Wavelet Transformation and Deep Learning", "abstract": "The recent development in the wearable devices domain raised interest in wearable sensor-based human activity recognition systems research. This paper introduces a novel human activity recognition system that uses a unique feature extraction method combined with a deep learning network associated with an attention layer. One of the main contributions of this work is the time-wise division of sensor sequences into non-overlapping segments. Each segment is treated as a 2D image, and consequently, we apply image-based feature extraction techniques to it. This includes the use of two-dimensional discrete wavelet transformation to extract useful features from the sensor readings. Experimental results showed that the system outperforms the recognition rates and f1-scores reported in most recent studies in the literature. Specifically, we report recognition rates of 99.44% for the UCI-HAR dataset, respectively.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/HONET63146.2024.10822931?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/HONET63146.2024.10822931, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2158430845", "name": "Yaman Albadawi"}, {"authorId": "1805004", "name": "T. Shanableh"}]}
{"paperId": "03a00b2270f0bc0d2c410dc7124e73a107c3ca28", "url": "https://www.semanticscholar.org/paper/03a00b2270f0bc0d2c410dc7124e73a107c3ca28", "title": "Effective Sensor Selection for Human Activity Recognition via Shapley Value", "abstract": "Real-time human activity recognition is facing an ever-growing need for efficient sensor setup. Identifying a minimal sensor configuration can lead to cost savings and less intrusive equipment, ultimately improving the quality of the collected data. In this study, we introduce and assess a sensor selection approach that ranks sensors based on their relevance in human activity recognition (HAR) tasks. Our methodology utilizes the Shapley value - a widely adopted metric inspired by game theory - of sensor measurements to determine the importance of each sensor. To validate our approach, we assess the impact of sensor removal on the accuracy of XGBoost tree models, which are trained on a publicly available HAR dataset. Our experiments indicate that Shapley-based sensor ranking achieves a favorable cost-accuracy tradeoff allowing for a reduction by more than 50% in the number of exploited sensors without significantly affecting accuracy.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/MetroLivEnv60384.2024.10615860?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/MetroLivEnv60384.2024.10615860, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": null, "authors": [{"authorId": "2315150413", "name": "Elisa Borella"}, {"authorId": "2315151385", "name": "Umut Berk \u00c7akmak\u00e7i"}, {"authorId": "2315154824", "name": "Enrico Gottardis"}, {"authorId": "30946067", "name": "Alessandro Buratto"}, {"authorId": "2311718194", "name": "Thomas Marchioro"}, {"authorId": "2276894648", "name": "Leonardo Badia"}]}
{"paperId": "0948d047c1961e4793322e1ad173f5b41e151676", "url": "https://www.semanticscholar.org/paper/0948d047c1961e4793322e1ad173f5b41e151676", "title": "Belief-Rule-Based System With Self-Organizing and Multi-Temporal Modeling for Sensor-Based Human Activity Recognition", "abstract": "Smart environment is an efficient and cost-effective way to afford intelligent supports for the elderly people. Human activity recognition is a crucial aspect of the research field of smart environments, and it has attracted widespread attention lately. The goal of this study is to develop an effective sensor-based human activity recognition model based on the belief-rule-based system (BRBS), which is one of representative rule-based expert systems. Specially, a new belief rule base (BRB) modeling approach is proposed by taking into account the self- organizing rule generation method and the multi-temporal rule representation scheme, in order to address the problem of combination explosion that existed in the traditional BRB modelling procedure and the time correlation found in continuous sensor data in chronological order. The new BRB modeling approach is so called self-organizing and multi-temporal BRB (SOMT-BRB) modeling procedure. A case study is further deducted to validate the effectiveness of the SOMT-BRB modeling procedure. By comparing with some conventional BRBSs and classical activity recognition models, the results show a significant improvement of the BRBS in terms of the number of belief rules, modelling efficiency, and activity recognition accuracy.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JBHI.2024.3485871?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JBHI.2024.3485871, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "66031829", "name": "Long-Hao Yang"}, {"authorId": "14994272", "name": "Fei-Fei Ye"}, {"authorId": "2294553131", "name": "Chris Nugent"}, {"authorId": "2286712272", "name": "Jun Liu"}, {"authorId": "2278401331", "name": "Ying-Ming Wang"}]}
{"paperId": "e94d79474dee24c9668d4fa1a77c361fcafaf056", "url": "https://www.semanticscholar.org/paper/e94d79474dee24c9668d4fa1a77c361fcafaf056", "title": "EGTCN: An Efficient Graph and Temporal Convolution Network for Sensor-Based Human Activity Recognition in Federated Learning", "abstract": "Technology advancements have led to the emergence of edge devices, wearable sensors, and the Internet of Things (IoT) that have revolutionized how we interact with technology. These devices enable real-time monitoring and analysis of human activities, leading to wearable sensor-based human activity recognition (HAR). Several recognition models are proposed for federated learning to protect users\u2019 privacy and improve the efficiency of activity recognition predictive models. However, these models have large parameters, yet their prediction results require improvement. In addition, these previous federated learning works do not consider the framewise classification of activity sensor data. This work presents an efficient graph and temporal convolution network (EGTCN) model that guarantees better recognition performance with less computation cost. In addition, EGTCN parallelly predicts activities of sensor segments just as other state-of-the-art (SOTA) methods and performs framewise prediction of the sensor data. EGTCN comprises the encoder, decoder, and classifier modules. The encoder, constructed from multigraph convolution (MGC) and multitemporal convolution (MTC) modules, mines essential features from the segment input. The decoder takes the encoder output to reconstruct and predict the activities of each frame within a segment. Similarly, the classifier module uses the encoder output to predict the activity category of the segment input as a whole. Moreover, we design a federated learning system (FLS) that ensures user privacy and improves the performance of activity recognition models. Benchmark sensor datasets, namely, WISDM, UCI-HAR, PAMAP2, RealWorld, and USCHAD, are utilized to evaluate the performance of our method. The results indicate that our EGTCN and FLS outperform SOTA methods.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/JSEN.2024.3446290?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JSEN.2024.3446290, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2105292212", "name": "S. B. Yussif"}, {"authorId": "2268349981", "name": "Ning Xie"}, {"authorId": "2152283122", "name": "Yang Yang"}, {"authorId": "2318985828", "name": "Yanbin Huang"}, {"authorId": "2268374215", "name": "Guan Wang"}, {"authorId": "2051288662", "name": "Zhenjiang Du"}]}
{"paperId": "9c5d53b90408c9928da6d9585388d7467cffc745", "url": "https://www.semanticscholar.org/paper/9c5d53b90408c9928da6d9585388d7467cffc745", "title": "Human Activity Recognition Using Spectrograms of Binary Motion Sensor Data", "abstract": "Human activity recognition is at the basis of several applications in the smart living domain, such as energy management, elder care, and health management. Human activity recognition research can be divided into two categories, depending on the type of sensors used: wearable sensors, such as those found in mobile phones and smart watches, and ambient sensors, such as motion sensors or cameras placed in the environment. Among ambient sensors, binary sensors are often perceived as less invasive than sensors that collect video, audio, or biometric data. However, the performance of classifiers trained on binary sensor data is often lower since the data inherently contains less information. In this paper, we propose a non-intrusive human activity recognition framework that only exploits binary sensor data and results in high classification accuracy. Our approach is inspired by audio and image processing applied to binary sensors. Specifically, we exploit the Short-Time Fourier Transform (STFT) to extract features from binary data. These features are used to train a hybrid machine learning model which pairs Convolutional Neural Network (CNN) with a Long-Short-Term Memory (LTSM) architecture. We use a real dataset of human activities monitored through binary sensor data for evaluating the impact of the features on classifier performance. Results show that the proposed method significantly outperforms state-of-the-art solutions, requiring minimal training data needed to achieve a given level of accuracy.", "openAccessPdf": {"url": "", "status": null, "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/DCOSS-IoT61029.2024.00063?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/DCOSS-IoT61029.2024.00063, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle", "Conference"], "authors": [{"authorId": "1387988457", "name": "Nima Seyedtalebi"}, {"authorId": "2316059554", "name": "Simone Silvestri"}]}
{"paperId": "5015b93a0632f41635cb89e1fc78b271f626855d", "url": "https://www.semanticscholar.org/paper/5015b93a0632f41635cb89e1fc78b271f626855d", "title": "Human Activity Recognition Using Flexible Sensor and Tiny Convolutional Neural Network", "abstract": "A tiny Convolutional Neural Network (CNN) for Human Activity Recognition (HAR), based on a single wearable flexible sensor applied to the knee joint, is presented; it is capable to distinguish three activities taken from a public dataset (w-HAR): jump, walk, sit. HAR has gained increasing interest in recent years, particularly with the widespread adoption of Artificial Intelligence and Neural Networks. A defining characteristic of this research domain is its versatility, spanning various fields, including healthcare and sports. The signal processing introduced in this work involves a grey-scale image encoding followed by a tiny CNN that consists of only one Convolutional layer. Activation functions employ a leaky ReLU while a Softmax function was used as a nonlinear component. Notably, during training the images were grey-scale encoded through a normalization while for the validation and test the images were built only with a routing of the time series data. Results in terms of test accuracy (94.43%) suggest the potentiality of HAR based on flexible and stretchable sensors using innovative image processing deep learning techniques and tiny CNN that could lead to intelligent sensors integrated with embedded AI capabilities.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/IFETC61155.2024.10771878?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IFETC61155.2024.10771878, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2308300067", "name": "Giuseppe Longo"}, {"authorId": "2307683478", "name": "Andrea Fasolino"}, {"authorId": "31035099", "name": "R. Liguori"}, {"authorId": "120417424", "name": "L. Di Benedetto"}, {"authorId": "2279844525", "name": "Alfredo Rubino"}, {"authorId": "2066261", "name": "G. Licciardo"}]}
{"paperId": "9a89ac593e887bc8da75a0ddd6d9e4fcf8eda6d8", "url": "https://www.semanticscholar.org/paper/9a89ac593e887bc8da75a0ddd6d9e4fcf8eda6d8", "title": "Effect of Sliding Window Sizes on Sensor-Based Human Activity Recognition Using Smartwatch Sensors and Deep Learning Approaches", "abstract": "Smartwatch sensors for human activity recognition (HAR) have gained significant attention due to their applications in healthcare and fitness monitoring. The effectiveness of HAR systems largely depends on the choice of sliding window widths for sensor data segmentation. This study investigates the impact of varying sliding window widths on the accuracy of HAR using wristwatch sensors and deep learning techniques. We conducted experiments using the daily human activity (DHA) dataset, comprising sensor data from 11 distinct activities. Data was preprocessed and segmented using window sizes ranging from 5 to 40 seconds. Four deep learning models (CNN, LSTM, BiLSTM, and CNN-LSTM) were employed and evaluated using accuracy, precision, recall, and F1-score. Window size significantly affected HAR performance. Smaller windows improved short-duration activity recognition but increased computational complexity, while larger windows reduced computational load but decreased accuracy for rapid activity changes. The CNN-LSTM hybrid model consistently outperformed other models, achieving 92.11% accuracy with a 20-second window and overlapping segmentation. This research provides valuable insights into balancing recognition accuracy and computational resources in smartwatch sensor-based HAR, contributing to the development of efficient and accurate systems for real-world applications.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/IBDAP62940.2024.10689691?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IBDAP62940.2024.10689691, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "9130999", "name": "S. Mekruksavanich"}, {"authorId": "2131076643", "name": "Ponnipa Jantawong"}, {"authorId": "9223341", "name": "A. Jitpattanakul"}]}
{"paperId": "134d8f57a211b4a58972be9f48123799a671516a", "url": "https://www.semanticscholar.org/paper/134d8f57a211b4a58972be9f48123799a671516a", "title": "Exploring Cutout and Mixup for Robust Human Activity Recognition on Sensor and Skeleton Data", "abstract": "Human Activity Recognition (HAR) is an essential area of research in Artificial Intelligence and Machine Learning, with numerous applications in healthcare, sports science, and smart environments. While several advancements in the field, such as attention-based models and Graph Neural Networks, have made great strides, this work focuses on data augmentation methods that tackle issues like data scarcity and task variability in HAR. In this work, we investigate and expand the use of mixup and cutout data augmentation methods to sensor-based and skeleton-based HAR datasets. These methods were first widely used in Computer Vision and Natural Language Processing. We use both augmentation techniques, customized for time-series and skeletal data, to improve the robustness and performance of HAR models by diversifying the data and overcoming the drawbacks of having limited training data. Specifically, we customize mixup data augmentation for sensor-based datasets and cutout data augmentation for skeleton-based datasets with the goal of improving model accuracy without adding more data. Our results show that using mixup and cutout techniques improves the accuracy and generalization of activity recognition models on both sensor-based and skeleton-based human activity datasets. This work showcases the potential of data augmentation techniques on transformers and Graph Neural Networks by offering a novel method for enhancing time series and skeletal HAR tasks.", "openAccessPdf": {"url": "https://www.mdpi.com/2076-3417/14/22/10286/pdf?version=1731064539", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/app142210286?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app142210286, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2226540064", "name": "Hiskias Dingeto"}, {"authorId": "2308991289", "name": "Juntae Kim"}]}
{"paperId": "7de570b1ff4e5eaadf4bb5de00ac659ee78c95f3", "url": "https://www.semanticscholar.org/paper/7de570b1ff4e5eaadf4bb5de00ac659ee78c95f3", "title": "Efficient human activity recognition: A deep convolutional transformer-based contrastive self-supervised approach using wearable sensors", "abstract": null, "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1016/j.engappai.2024.108705?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1016/j.engappai.2024.108705, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "1390836636", "name": "Yujie Sun"}, {"authorId": "48670158", "name": "Xiaolong Xu"}, {"authorId": "2243793643", "name": "Xincheng Tian"}, {"authorId": "1983906", "name": "Lelai Zhou"}, {"authorId": "2243002996", "name": "Yibin Li"}]}
{"paperId": "7f9123441143886cffd0b0e0ef98bc5dbc005d3f", "url": "https://www.semanticscholar.org/paper/7f9123441143886cffd0b0e0ef98bc5dbc005d3f", "title": "Optimized Convolutional Neural Network Using Hierarchical Particle Swarm Optimization for Sensor Based Human Activity Recognition", "abstract": null, "openAccessPdf": {"url": "https://link.springer.com/content/pdf/10.1007/s42979-024-02794-5.pdf", "status": "HYBRID", "license": "CCBY", "disclaimer": "Notice: This paper's abstract has been elided by the publisher. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s42979-024-02794-5?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s42979-024-02794-5, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "9286397", "name": "Shilpa Ankalaki"}, {"authorId": "2297535979", "name": "M. N. Thippeswamy"}]}
{"paperId": "25d3e96f19656114ec7eb36c48d680e8e25f4f0b", "url": "https://www.semanticscholar.org/paper/25d3e96f19656114ec7eb36c48d680e8e25f4f0b", "title": "Human activity recognition using a single-photon direct time-of-flight sensor.", "abstract": "Single-Photon Avalanche Diode (SPAD) direct Time-of-Flight (dToF) sensors provide depth imaging over long distances, enabling the detection of objects even in the absence of contrast in colour or texture. However, distant objects are represented by just a few pixels and are subject to noise from solar interference, limiting the applicability of existing computer vision techniques for high-level scene interpretation. We present a new SPAD-based vision system for human activity recognition, based on convolutional and recurrent neural networks, which is trained entirely on synthetic data. In tests using real data from a 64\u00d732 pixel SPAD, captured over a distance of 40 m, the scheme successfully overcomes the limited transverse resolution (in which human limbs are approximately one pixel across), achieving an average accuracy of 89% in distinguishing between seven different activities. The approach analyses continuous streams of video-rate depth data at a maximal rate of 66 FPS when executed on a GPU, making it well-suited for real-time applications such as surveillance or situational awareness in autonomous systems.", "openAccessPdf": {"url": "https://doi.org/10.1364/oe.516681", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1364/oe.516681?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1364/oe.516681, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "1471018247", "name": "Germ\u00e1n Mora-Mart\u00edn"}, {"authorId": "38902487", "name": "S. Scholes"}, {"authorId": "2257307886", "name": "Robert K. Henderson"}, {"authorId": "2144871848", "name": "Jonathan Leach"}, {"authorId": "6588375", "name": "I. Gyongy"}]}
{"paperId": "7066e76ef4a2e7ebf7dd55fa61f649f833cadf48", "url": "https://www.semanticscholar.org/paper/7066e76ef4a2e7ebf7dd55fa61f649f833cadf48", "title": "Human activity recognition: an approach 2D CNN-LSTM to sequential image representation and processing of inertial sensor data", "abstract": "The field of human activity recognition, abbreviated as HAR, benefits significantly from deep learning by addressing the complexity of human behavior and the vast volume of data produced by sensors. This work adopted the strategy of converting inertial data, such as accelerometer and gyroscope signals, into 2D images through recurrence plots. This approach facilitated the effective exploration of data input and neural network architectures. By utilizing the recent history of movements as input for the models, this study evaluated the impact of this methodology on HAR using two adapted architectures: 2D convolutional neural networks combined with long short-term memory layers (2D CNN-LSTM) and standalone 2D convolutional neural networks (2D CNN). Their performances were compared with other state-of-the-art deep learning models. The contributions of this study were threefold: the handling of input data, the development of the two network architectures for HAR, and the high accuracy achieved, ranging from 97% to 98%, on the public University of California, Irvine human activity recognition dataset (UCI-HAR). These results highlighted the benefit of incorporating temporal data to enhance accuracy in activity classification.", "openAccessPdf": {"url": "https://doi.org/10.3934/bioeng.2024024", "status": "GOLD", "license": "CCBY", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3934/bioeng.2024024?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3934/bioeng.2024024, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2333737310", "name": "Wallace Camacho Carlos"}, {"authorId": "2078462920", "name": "Alessandro Copetti"}, {"authorId": "2271252809", "name": "Luciano Bertini"}, {"authorId": "2270540393", "name": "Leonard Barreto Moreira"}, {"authorId": "2333742794", "name": "Ot\u00e1vio de Souza Martins Gomes"}]}
{"paperId": "c3ea6f3913dc1a449a1d14fa9d046322f04f4590", "url": "https://www.semanticscholar.org/paper/c3ea6f3913dc1a449a1d14fa9d046322f04f4590", "title": "Gait-Based Human Activity Recognition Using Efficient Sensor Fusion and Deep Learning Approach", "abstract": "Human activity recognition is an important area of computer vision research. Its applications include surveillance systems, patient monitoring systems, and a variety of systems that involve interactions between persons and electronic devices such as human-computer interfaces. Most of these applications require an automated recognition of high-level activities, composed of multiple simple (or atomic) actions of persons. A novel feature selection approach is then proposed in order to select a subset of discriminant features, construct an online activity recognizer with better generalization ability, and reduce the smartphone power consumption. Experimental results on a publicly available data set show that the fusion of both accelerometer and gyroscope data contributes to obtain better recognition performance than that of using single source data, and that the proposed feature selector outperforms three other comparative approaches in terms of four performance measures. Such activity profiling systems are dependent on classification algorithms which can effectively interpret body-worn sensor data and identify different activities.\u00a0 the key research challenges that human activity recognition shares with general pattern recognition and identify those challenges that are specific to human activity recognition. The aim of paper is to explore real life applications like contactless employee recognition system using gait analysis which uses sensor data as base to identify employees based on their gait movement. This requires understanding the dimensions of sensor data and its application exploring other potential real-life applications and optimizing the methodology are also one of the core objectives.", "openAccessPdf": {"url": "https://journal.esrgroups.org/jes/article/download/3465/2710", "status": "HYBRID", "license": "CCBYND", "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.52783/jes.3465?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.52783/jes.3465, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["JournalArticle"], "authors": [{"authorId": "2302263459", "name": "Aniket Bandyopadhyay"}, {"authorId": "2302347298", "name": "Manoj Kumar"}]}
{"paperId": "5ff09fad00a7c5701f576d43de220ae897eeb96a", "url": "https://www.semanticscholar.org/paper/5ff09fad00a7c5701f576d43de220ae897eeb96a", "title": "Human Activity Recognition Using Sensor Measurements", "abstract": "Accelerometer and gyroscope readings are found to be ubiquitously used for human activity recognition. These sensors are found to complement each other and increase the performance in determining the location and movement of an individual. In this work, the efficiency of multiple machine learning models is tested against six different human activities. Results show that the machine learning models have the ability of differentiating the human activities. The k-NN model is found to have an accuracy of 79.5% while the tree-based machine learning models resulted in an accuracy of 97.7%, which is comparatively high. The distance metric used in k-NN might have a significant role in determining the classes but it fails to handle the non-linearity in data. Finally, this study concludes that the tree based machine learning models are highly suitable for human activity recognition.", "openAccessPdf": {"url": "", "status": "CLOSED", "license": null, "disclaimer": "Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICOECA62351.2024.00104?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICOECA62351.2024.00104, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."}, "publicationTypes": ["Conference"], "authors": [{"authorId": "2315035395", "name": "Karthick Saran J"}, {"authorId": null, "name": "Mayilsamy M"}, {"authorId": "2314975618", "name": "Riyash Ahamed M"}, {"authorId": "2261958671", "name": "Ramesh Munirathinam"}]}
